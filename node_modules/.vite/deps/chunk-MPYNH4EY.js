import {
  Amplify,
  AmplifyError,
  AmplifyErrorCode,
  AmplifyUrl,
  AmplifyUrlSearchParams,
  Category,
  ConsoleLogger,
  EMPTY_HASH,
  StorageAction,
  amzSdkInvocationIdHeaderMiddlewareFactory,
  amzSdkRequestHeaderMiddlewareFactory,
  composeServiceApi,
  composeTransferHandler,
  defaultStorage,
  extendedEncodeURIComponent,
  getAmplifyUserAgent,
  getDnsSuffix,
  getHashedPayload,
  getRetryDecider,
  jitteredBackoff,
  parseMetadata,
  presignUrl,
  retryMiddlewareFactory,
  signingMiddlewareFactory,
  userAgentMiddlewareFactory,
  withMemoization
} from "./chunk-PCMRQHIL.js";
import {
  __commonJS,
  __toESM
} from "./chunk-G3PMV62Z.js";

// browser-external:fast-xml-parser
var require_fast_xml_parser = __commonJS({
  "browser-external:fast-xml-parser"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "fast-xml-parser" has been externalized for browser compatibility. Cannot access "fast-xml-parser.${key}" in client code. See https://vite.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// browser-external:buffer
var require_buffer = __commonJS({
  "browser-external:buffer"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "buffer" has been externalized for browser compatibility. Cannot access "buffer.${key}" in client code. See https://vite.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// node_modules/crc-32/crc32.js
var require_crc32 = __commonJS({
  "node_modules/crc-32/crc32.js"(exports) {
    var CRC32;
    (function(factory) {
      if (typeof DO_NOT_EXPORT_CRC === "undefined") {
        if ("object" === typeof exports) {
          factory(exports);
        } else if ("function" === typeof define && define.amd) {
          define(function() {
            var module2 = {};
            factory(module2);
            return module2;
          });
        } else {
          factory(CRC32 = {});
        }
      } else {
        factory(CRC32 = {});
      }
    })(function(CRC322) {
      CRC322.version = "1.2.2";
      function signed_crc_table() {
        var c = 0, table = new Array(256);
        for (var n = 0; n != 256; ++n) {
          c = n;
          c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;
          c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;
          c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;
          c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;
          c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;
          c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;
          c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;
          c = c & 1 ? -306674912 ^ c >>> 1 : c >>> 1;
          table[n] = c;
        }
        return typeof Int32Array !== "undefined" ? new Int32Array(table) : table;
      }
      var T0 = signed_crc_table();
      function slice_by_16_tables(T) {
        var c = 0, v = 0, n = 0, table = typeof Int32Array !== "undefined" ? new Int32Array(4096) : new Array(4096);
        for (n = 0; n != 256; ++n) table[n] = T[n];
        for (n = 0; n != 256; ++n) {
          v = T[n];
          for (c = 256 + n; c < 4096; c += 256) v = table[c] = v >>> 8 ^ T[v & 255];
        }
        var out = [];
        for (n = 1; n != 16; ++n) out[n - 1] = typeof Int32Array !== "undefined" ? table.subarray(n * 256, n * 256 + 256) : table.slice(n * 256, n * 256 + 256);
        return out;
      }
      var TT = slice_by_16_tables(T0);
      var T1 = TT[0], T2 = TT[1], T3 = TT[2], T4 = TT[3], T5 = TT[4];
      var T6 = TT[5], T7 = TT[6], T8 = TT[7], T9 = TT[8], Ta = TT[9];
      var Tb = TT[10], Tc = TT[11], Td = TT[12], Te = TT[13], Tf = TT[14];
      function crc32_bstr(bstr, seed) {
        var C = seed ^ -1;
        for (var i = 0, L = bstr.length; i < L; ) C = C >>> 8 ^ T0[(C ^ bstr.charCodeAt(i++)) & 255];
        return ~C;
      }
      function crc32_buf(B, seed) {
        var C = seed ^ -1, L = B.length - 15, i = 0;
        for (; i < L; ) C = Tf[B[i++] ^ C & 255] ^ Te[B[i++] ^ C >> 8 & 255] ^ Td[B[i++] ^ C >> 16 & 255] ^ Tc[B[i++] ^ C >>> 24] ^ Tb[B[i++]] ^ Ta[B[i++]] ^ T9[B[i++]] ^ T8[B[i++]] ^ T7[B[i++]] ^ T6[B[i++]] ^ T5[B[i++]] ^ T4[B[i++]] ^ T3[B[i++]] ^ T2[B[i++]] ^ T1[B[i++]] ^ T0[B[i++]];
        L += 15;
        while (i < L) C = C >>> 8 ^ T0[(C ^ B[i++]) & 255];
        return ~C;
      }
      function crc32_str(str, seed) {
        var C = seed ^ -1;
        for (var i = 0, L = str.length, c = 0, d = 0; i < L; ) {
          c = str.charCodeAt(i++);
          if (c < 128) {
            C = C >>> 8 ^ T0[(C ^ c) & 255];
          } else if (c < 2048) {
            C = C >>> 8 ^ T0[(C ^ (192 | c >> 6 & 31)) & 255];
            C = C >>> 8 ^ T0[(C ^ (128 | c & 63)) & 255];
          } else if (c >= 55296 && c < 57344) {
            c = (c & 1023) + 64;
            d = str.charCodeAt(i++) & 1023;
            C = C >>> 8 ^ T0[(C ^ (240 | c >> 8 & 7)) & 255];
            C = C >>> 8 ^ T0[(C ^ (128 | c >> 2 & 63)) & 255];
            C = C >>> 8 ^ T0[(C ^ (128 | d >> 6 & 15 | (c & 3) << 4)) & 255];
            C = C >>> 8 ^ T0[(C ^ (128 | d & 63)) & 255];
          } else {
            C = C >>> 8 ^ T0[(C ^ (224 | c >> 12 & 15)) & 255];
            C = C >>> 8 ^ T0[(C ^ (128 | c >> 6 & 63)) & 255];
            C = C >>> 8 ^ T0[(C ^ (128 | c & 63)) & 255];
          }
        }
        return ~C;
      }
      CRC322.table = T0;
      CRC322.bstr = crc32_bstr;
      CRC322.buf = crc32_buf;
      CRC322.str = crc32_str;
    });
  }
});

// node_modules/@aws-amplify/storage/node_modules/@smithy/util-utf8/dist-es/fromUtf8.browser.js
var fromUtf8 = (input) => new TextEncoder().encode(input);

// node_modules/@aws-amplify/storage/node_modules/@smithy/md5-js/dist-es/constants.js
var BLOCK_SIZE = 64;
var DIGEST_LENGTH = 16;
var INIT = [1732584193, 4023233417, 2562383102, 271733878];

// node_modules/@aws-amplify/storage/node_modules/@smithy/md5-js/dist-es/index.js
var Md5 = class {
  constructor() {
    this.reset();
  }
  update(sourceData) {
    if (isEmptyData(sourceData)) {
      return;
    } else if (this.finished) {
      throw new Error("Attempted to update an already finished hash.");
    }
    const data = convertToBuffer(sourceData);
    let position = 0;
    let { byteLength: byteLength2 } = data;
    this.bytesHashed += byteLength2;
    while (byteLength2 > 0) {
      this.buffer.setUint8(this.bufferLength++, data[position++]);
      byteLength2--;
      if (this.bufferLength === BLOCK_SIZE) {
        this.hashBuffer();
        this.bufferLength = 0;
      }
    }
  }
  async digest() {
    if (!this.finished) {
      const { buffer, bufferLength: undecoratedLength, bytesHashed } = this;
      const bitsHashed = bytesHashed * 8;
      buffer.setUint8(this.bufferLength++, 128);
      if (undecoratedLength % BLOCK_SIZE >= BLOCK_SIZE - 8) {
        for (let i = this.bufferLength; i < BLOCK_SIZE; i++) {
          buffer.setUint8(i, 0);
        }
        this.hashBuffer();
        this.bufferLength = 0;
      }
      for (let i = this.bufferLength; i < BLOCK_SIZE - 8; i++) {
        buffer.setUint8(i, 0);
      }
      buffer.setUint32(BLOCK_SIZE - 8, bitsHashed >>> 0, true);
      buffer.setUint32(BLOCK_SIZE - 4, Math.floor(bitsHashed / 4294967296), true);
      this.hashBuffer();
      this.finished = true;
    }
    const out = new DataView(new ArrayBuffer(DIGEST_LENGTH));
    for (let i = 0; i < 4; i++) {
      out.setUint32(i * 4, this.state[i], true);
    }
    return new Uint8Array(out.buffer, out.byteOffset, out.byteLength);
  }
  hashBuffer() {
    const { buffer, state } = this;
    let a = state[0], b = state[1], c = state[2], d = state[3];
    a = ff(a, b, c, d, buffer.getUint32(0, true), 7, 3614090360);
    d = ff(d, a, b, c, buffer.getUint32(4, true), 12, 3905402710);
    c = ff(c, d, a, b, buffer.getUint32(8, true), 17, 606105819);
    b = ff(b, c, d, a, buffer.getUint32(12, true), 22, 3250441966);
    a = ff(a, b, c, d, buffer.getUint32(16, true), 7, 4118548399);
    d = ff(d, a, b, c, buffer.getUint32(20, true), 12, 1200080426);
    c = ff(c, d, a, b, buffer.getUint32(24, true), 17, 2821735955);
    b = ff(b, c, d, a, buffer.getUint32(28, true), 22, 4249261313);
    a = ff(a, b, c, d, buffer.getUint32(32, true), 7, 1770035416);
    d = ff(d, a, b, c, buffer.getUint32(36, true), 12, 2336552879);
    c = ff(c, d, a, b, buffer.getUint32(40, true), 17, 4294925233);
    b = ff(b, c, d, a, buffer.getUint32(44, true), 22, 2304563134);
    a = ff(a, b, c, d, buffer.getUint32(48, true), 7, 1804603682);
    d = ff(d, a, b, c, buffer.getUint32(52, true), 12, 4254626195);
    c = ff(c, d, a, b, buffer.getUint32(56, true), 17, 2792965006);
    b = ff(b, c, d, a, buffer.getUint32(60, true), 22, 1236535329);
    a = gg(a, b, c, d, buffer.getUint32(4, true), 5, 4129170786);
    d = gg(d, a, b, c, buffer.getUint32(24, true), 9, 3225465664);
    c = gg(c, d, a, b, buffer.getUint32(44, true), 14, 643717713);
    b = gg(b, c, d, a, buffer.getUint32(0, true), 20, 3921069994);
    a = gg(a, b, c, d, buffer.getUint32(20, true), 5, 3593408605);
    d = gg(d, a, b, c, buffer.getUint32(40, true), 9, 38016083);
    c = gg(c, d, a, b, buffer.getUint32(60, true), 14, 3634488961);
    b = gg(b, c, d, a, buffer.getUint32(16, true), 20, 3889429448);
    a = gg(a, b, c, d, buffer.getUint32(36, true), 5, 568446438);
    d = gg(d, a, b, c, buffer.getUint32(56, true), 9, 3275163606);
    c = gg(c, d, a, b, buffer.getUint32(12, true), 14, 4107603335);
    b = gg(b, c, d, a, buffer.getUint32(32, true), 20, 1163531501);
    a = gg(a, b, c, d, buffer.getUint32(52, true), 5, 2850285829);
    d = gg(d, a, b, c, buffer.getUint32(8, true), 9, 4243563512);
    c = gg(c, d, a, b, buffer.getUint32(28, true), 14, 1735328473);
    b = gg(b, c, d, a, buffer.getUint32(48, true), 20, 2368359562);
    a = hh(a, b, c, d, buffer.getUint32(20, true), 4, 4294588738);
    d = hh(d, a, b, c, buffer.getUint32(32, true), 11, 2272392833);
    c = hh(c, d, a, b, buffer.getUint32(44, true), 16, 1839030562);
    b = hh(b, c, d, a, buffer.getUint32(56, true), 23, 4259657740);
    a = hh(a, b, c, d, buffer.getUint32(4, true), 4, 2763975236);
    d = hh(d, a, b, c, buffer.getUint32(16, true), 11, 1272893353);
    c = hh(c, d, a, b, buffer.getUint32(28, true), 16, 4139469664);
    b = hh(b, c, d, a, buffer.getUint32(40, true), 23, 3200236656);
    a = hh(a, b, c, d, buffer.getUint32(52, true), 4, 681279174);
    d = hh(d, a, b, c, buffer.getUint32(0, true), 11, 3936430074);
    c = hh(c, d, a, b, buffer.getUint32(12, true), 16, 3572445317);
    b = hh(b, c, d, a, buffer.getUint32(24, true), 23, 76029189);
    a = hh(a, b, c, d, buffer.getUint32(36, true), 4, 3654602809);
    d = hh(d, a, b, c, buffer.getUint32(48, true), 11, 3873151461);
    c = hh(c, d, a, b, buffer.getUint32(60, true), 16, 530742520);
    b = hh(b, c, d, a, buffer.getUint32(8, true), 23, 3299628645);
    a = ii(a, b, c, d, buffer.getUint32(0, true), 6, 4096336452);
    d = ii(d, a, b, c, buffer.getUint32(28, true), 10, 1126891415);
    c = ii(c, d, a, b, buffer.getUint32(56, true), 15, 2878612391);
    b = ii(b, c, d, a, buffer.getUint32(20, true), 21, 4237533241);
    a = ii(a, b, c, d, buffer.getUint32(48, true), 6, 1700485571);
    d = ii(d, a, b, c, buffer.getUint32(12, true), 10, 2399980690);
    c = ii(c, d, a, b, buffer.getUint32(40, true), 15, 4293915773);
    b = ii(b, c, d, a, buffer.getUint32(4, true), 21, 2240044497);
    a = ii(a, b, c, d, buffer.getUint32(32, true), 6, 1873313359);
    d = ii(d, a, b, c, buffer.getUint32(60, true), 10, 4264355552);
    c = ii(c, d, a, b, buffer.getUint32(24, true), 15, 2734768916);
    b = ii(b, c, d, a, buffer.getUint32(52, true), 21, 1309151649);
    a = ii(a, b, c, d, buffer.getUint32(16, true), 6, 4149444226);
    d = ii(d, a, b, c, buffer.getUint32(44, true), 10, 3174756917);
    c = ii(c, d, a, b, buffer.getUint32(8, true), 15, 718787259);
    b = ii(b, c, d, a, buffer.getUint32(36, true), 21, 3951481745);
    state[0] = a + state[0] & 4294967295;
    state[1] = b + state[1] & 4294967295;
    state[2] = c + state[2] & 4294967295;
    state[3] = d + state[3] & 4294967295;
  }
  reset() {
    this.state = Uint32Array.from(INIT);
    this.buffer = new DataView(new ArrayBuffer(BLOCK_SIZE));
    this.bufferLength = 0;
    this.bytesHashed = 0;
    this.finished = false;
  }
};
function cmn(q, a, b, x, s, t) {
  a = (a + q & 4294967295) + (x + t & 4294967295) & 4294967295;
  return (a << s | a >>> 32 - s) + b & 4294967295;
}
function ff(a, b, c, d, x, s, t) {
  return cmn(b & c | ~b & d, a, b, x, s, t);
}
function gg(a, b, c, d, x, s, t) {
  return cmn(b & d | c & ~d, a, b, x, s, t);
}
function hh(a, b, c, d, x, s, t) {
  return cmn(b ^ c ^ d, a, b, x, s, t);
}
function ii(a, b, c, d, x, s, t) {
  return cmn(c ^ (b | ~d), a, b, x, s, t);
}
function isEmptyData(data) {
  if (typeof data === "string") {
    return data.length === 0;
  }
  return data.byteLength === 0;
}
function convertToBuffer(data) {
  if (typeof data === "string") {
    return fromUtf8(data);
  }
  if (ArrayBuffer.isView(data)) {
    return new Uint8Array(data.buffer, data.byteOffset, data.byteLength / Uint8Array.BYTES_PER_ELEMENT);
  }
  return new Uint8Array(data);
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/runtime/constants.mjs
var NETWORK_ERROR_MESSAGE = "Network Error";
var NETWORK_ERROR_CODE = "ERR_NETWORK";
var ABORT_ERROR_MESSAGE = "Request aborted";
var ABORT_ERROR_CODE = "ERR_ABORTED";
var CANCELED_ERROR_MESSAGE = "canceled";
var CANCELED_ERROR_CODE = "ERR_CANCELED";
var CONTENT_SHA256_HEADER = "x-amz-content-sha256";

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/runtime/contentSha256middleware.mjs
var contentSha256MiddlewareFactory = () => (next) => async function contentSha256Middleware(request) {
  if (request.headers[CONTENT_SHA256_HEADER]) {
    return next(request);
  } else {
    const hash = await getHashedPayload(request.body);
    request.headers[CONTENT_SHA256_HEADER] = hash;
    return next(request);
  }
};

// node_modules/@aws-amplify/storage/dist/esm/errors/StorageError.mjs
var StorageError = class _StorageError extends AmplifyError {
  constructor(params) {
    super(params);
    this.constructor = _StorageError;
    Object.setPrototypeOf(this, _StorageError.prototype);
  }
};

// node_modules/@aws-amplify/storage/dist/esm/errors/CanceledError.mjs
var CanceledError = class _CanceledError extends StorageError {
  constructor(params = {}) {
    super({
      name: "CanceledError",
      message: "Upload is canceled by user",
      ...params
    });
    this.constructor = _CanceledError;
    Object.setPrototypeOf(this, _CanceledError.prototype);
  }
};
var isCancelError = (error) => !!error && error instanceof CanceledError;

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/runtime/xhrTransferHandler.mjs
var logger = new ConsoleLogger("xhr-http-handler");
var xhrTransferHandler = (request, options) => {
  const { url, method, headers, body } = request;
  const { onDownloadProgress, onUploadProgress, responseType, abortSignal } = options;
  return new Promise((resolve, reject) => {
    let xhr = new XMLHttpRequest();
    xhr.open(method.toUpperCase(), url.toString());
    Object.entries(headers).filter(([header]) => !FORBIDDEN_HEADERS.includes(header)).forEach(([header, value]) => {
      xhr.setRequestHeader(header, value);
    });
    xhr.responseType = responseType;
    if (onDownloadProgress) {
      xhr.addEventListener("progress", (event) => {
        onDownloadProgress(convertToTransferProgressEvent(event));
        logger.debug(event);
      });
    }
    if (onUploadProgress) {
      xhr.upload.addEventListener("progress", (event) => {
        onUploadProgress(convertToTransferProgressEvent(event));
        logger.debug(event);
      });
    }
    xhr.addEventListener("error", () => {
      const networkError = new StorageError({
        message: NETWORK_ERROR_MESSAGE,
        name: NETWORK_ERROR_CODE
      });
      logger.error(NETWORK_ERROR_MESSAGE);
      reject(networkError);
      xhr = null;
    });
    xhr.addEventListener("abort", () => {
      if (!xhr || (abortSignal == null ? void 0 : abortSignal.aborted))
        return;
      const error = buildHandlerError(ABORT_ERROR_MESSAGE, ABORT_ERROR_CODE);
      logger.error(ABORT_ERROR_MESSAGE);
      reject(error);
      xhr = null;
    });
    xhr.addEventListener("readystatechange", () => {
      if (!xhr || xhr.readyState !== xhr.DONE) {
        return;
      }
      const onloadend = () => {
        if (!xhr)
          return;
        const responseHeaders = convertResponseHeaders(xhr.getAllResponseHeaders());
        const { responseType: loadEndResponseType } = xhr;
        const responseBlob = xhr.response;
        const responseText = loadEndResponseType === "text" ? xhr.responseText : "";
        const bodyMixIn = {
          blob: () => Promise.resolve(responseBlob),
          text: withMemoization(() => loadEndResponseType === "blob" ? readBlobAsText(responseBlob) : Promise.resolve(responseText)),
          json: () => Promise.reject(
            // S3 does not support JSON response. So fail-fast here with nicer error message.
            new Error("Parsing response to JSON is not implemented. Please use response.text() instead.")
          )
        };
        const response = {
          statusCode: xhr.status,
          headers: responseHeaders,
          // The xhr.responseType is only set to 'blob' for streaming binary S3 object data. The streaming data is
          // exposed via public interface of Storage.get(). So we need to return the response as a Blob object for
          // backward compatibility. In other cases, the response payload is only used internally, we return it is
          // {@link ResponseBodyMixin}
          body: xhr.responseType === "blob" ? Object.assign(responseBlob, bodyMixIn) : bodyMixIn
        };
        resolve(response);
        xhr = null;
      };
      setTimeout(onloadend);
    });
    if (abortSignal) {
      const onCanceled = () => {
        if (!xhr) {
          return;
        }
        const canceledError = new CanceledError({
          name: CANCELED_ERROR_CODE,
          message: CANCELED_ERROR_MESSAGE
        });
        reject(canceledError);
        xhr.abort();
        xhr = null;
      };
      abortSignal.aborted ? onCanceled() : abortSignal.addEventListener("abort", onCanceled);
    }
    if (typeof ReadableStream === "function" && body instanceof ReadableStream) {
      throw new Error("ReadableStream request payload is not supported.");
    }
    xhr.send(body ?? null);
  });
};
var convertToTransferProgressEvent = (event) => ({
  transferredBytes: event.loaded,
  totalBytes: event.lengthComputable ? event.total : void 0
});
var buildHandlerError = (message, name) => {
  const error = new Error(message);
  error.name = name;
  return error;
};
var convertResponseHeaders = (xhrHeaders) => {
  if (!xhrHeaders) {
    return {};
  }
  return xhrHeaders.split("\r\n").reduce((headerMap, line) => {
    const parts = line.split(": ");
    const header = parts.shift();
    const value = parts.join(": ");
    headerMap[header.toLowerCase()] = value;
    return headerMap;
  }, {});
};
var readBlobAsText = (blob) => {
  const reader = new FileReader();
  return new Promise((resolve, reject) => {
    reader.onloadend = () => {
      if (reader.readyState !== FileReader.DONE) {
        return;
      }
      resolve(reader.result);
    };
    reader.onerror = () => {
      reject(reader.error);
    };
    reader.readAsText(blob);
  });
};
var FORBIDDEN_HEADERS = ["host"];

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/runtime/s3TransferHandler/xhr.mjs
var s3TransferHandler = composeTransferHandler(xhrTransferHandler, [
  contentSha256MiddlewareFactory,
  userAgentMiddlewareFactory,
  amzSdkInvocationIdHeaderMiddlewareFactory,
  retryMiddlewareFactory,
  amzSdkRequestHeaderMiddlewareFactory,
  signingMiddlewareFactory
]);

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/index.mjs
var import_fast_xml_parser16 = __toESM(require_fast_xml_parser(), 1);
var import_buffer16 = __toESM(require_buffer(), 1);

// node_modules/@aws-amplify/storage/dist/esm/errors/types/validation.mjs
var StorageValidationErrorCode;
(function(StorageValidationErrorCode2) {
  StorageValidationErrorCode2["NoCredentials"] = "NoCredentials";
  StorageValidationErrorCode2["NoIdentityId"] = "NoIdentityId";
  StorageValidationErrorCode2["NoKey"] = "NoKey";
  StorageValidationErrorCode2["NoSourceKey"] = "NoSourceKey";
  StorageValidationErrorCode2["NoDestinationKey"] = "NoDestinationKey";
  StorageValidationErrorCode2["NoSourcePath"] = "NoSourcePath";
  StorageValidationErrorCode2["NoDestinationPath"] = "NoDestinationPath";
  StorageValidationErrorCode2["NoBucket"] = "NoBucket";
  StorageValidationErrorCode2["NoRegion"] = "NoRegion";
  StorageValidationErrorCode2["InvalidStorageBucket"] = "InvalidStorageBucket";
  StorageValidationErrorCode2["InvalidCopyOperationStorageBucket"] = "InvalidCopyOperationStorageBucket";
  StorageValidationErrorCode2["InvalidStorageOperationPrefixInput"] = "InvalidStorageOperationPrefixInput";
  StorageValidationErrorCode2["InvalidStorageOperationInput"] = "InvalidStorageOperationInput";
  StorageValidationErrorCode2["InvalidAWSAccountID"] = "InvalidAWSAccountID";
  StorageValidationErrorCode2["InvalidStoragePathInput"] = "InvalidStoragePathInput";
  StorageValidationErrorCode2["InvalidUploadSource"] = "InvalidUploadSource";
  StorageValidationErrorCode2["ObjectIsTooLarge"] = "ObjectIsTooLarge";
  StorageValidationErrorCode2["UrlExpirationMaxLimitExceed"] = "UrlExpirationMaxLimitExceed";
  StorageValidationErrorCode2["InvalidLocationCredentialsCacheSize"] = "InvalidLocationCredentialsCacheSize";
  StorageValidationErrorCode2["LocationCredentialsStoreDestroyed"] = "LocationCredentialsStoreDestroyed";
  StorageValidationErrorCode2["InvalidS3Uri"] = "InvalidS3Uri";
  StorageValidationErrorCode2["InvalidCustomEndpoint"] = "InvalidCustomEndpoint";
  StorageValidationErrorCode2["ForcePathStyleEndpointNotSupported"] = "ForcePathStyleEndpointNotSupported";
  StorageValidationErrorCode2["DnsIncompatibleBucketName"] = "DnsIncompatibleBucketName";
})(StorageValidationErrorCode || (StorageValidationErrorCode = {}));
var validationErrorMap = {
  [StorageValidationErrorCode.NoCredentials]: {
    message: "Credentials should not be empty."
  },
  [StorageValidationErrorCode.NoIdentityId]: {
    message: "Missing identity ID when accessing objects in protected or private access level."
  },
  [StorageValidationErrorCode.NoKey]: {
    message: "Missing key in api call."
  },
  [StorageValidationErrorCode.NoSourceKey]: {
    message: "Missing source key in copy api call."
  },
  [StorageValidationErrorCode.NoDestinationKey]: {
    message: "Missing destination key in copy api call."
  },
  [StorageValidationErrorCode.NoSourcePath]: {
    message: "Missing source path in copy api call."
  },
  [StorageValidationErrorCode.NoDestinationPath]: {
    message: "Missing destination path in copy api call."
  },
  [StorageValidationErrorCode.NoBucket]: {
    message: "Missing bucket name while accessing object."
  },
  [StorageValidationErrorCode.NoRegion]: {
    message: "Missing region while accessing object."
  },
  [StorageValidationErrorCode.UrlExpirationMaxLimitExceed]: {
    message: "Url Expiration can not be greater than 7 Days."
  },
  [StorageValidationErrorCode.ObjectIsTooLarge]: {
    message: "Object size cannot not be greater than 5TB."
  },
  [StorageValidationErrorCode.InvalidUploadSource]: {
    message: "Upload source type can only be a `Blob`, `File`, `ArrayBuffer`, or `string`."
  },
  [StorageValidationErrorCode.InvalidStorageOperationInput]: {
    message: "Path or key parameter must be specified in the input. Both can not be specified at the same time."
  },
  [StorageValidationErrorCode.InvalidAWSAccountID]: {
    message: "Invalid AWS account ID was provided."
  },
  [StorageValidationErrorCode.InvalidStorageOperationPrefixInput]: {
    message: "Both path and prefix can not be specified at the same time."
  },
  [StorageValidationErrorCode.InvalidStoragePathInput]: {
    message: "Input `path` does not allow a leading slash (/)."
  },
  [StorageValidationErrorCode.InvalidLocationCredentialsCacheSize]: {
    message: "locationCredentialsCacheSize must be a positive integer."
  },
  [StorageValidationErrorCode.LocationCredentialsStoreDestroyed]: {
    message: `Location-specific credentials store has been destroyed.`
  },
  [StorageValidationErrorCode.InvalidS3Uri]: {
    message: "Invalid S3 URI."
  },
  [StorageValidationErrorCode.InvalidStorageBucket]: {
    message: "Unable to lookup bucket from provided name in Amplify configuration."
  },
  [StorageValidationErrorCode.InvalidCopyOperationStorageBucket]: {
    message: "Missing bucket option in either source or destination."
  },
  [StorageValidationErrorCode.InvalidCustomEndpoint]: {
    message: "Invalid S3 custom endpoint."
  },
  [StorageValidationErrorCode.ForcePathStyleEndpointNotSupported]: {
    message: "Path style URLs are not supported with S3 Transfer Acceleration."
  },
  [StorageValidationErrorCode.DnsIncompatibleBucketName]: {
    message: `The bucket name isn't DNS compatible.`
  }
};

// node_modules/@aws-amplify/storage/dist/esm/errors/utils/assertValidationError.mjs
function assertValidationError(assertion, name) {
  const { message, recoverySuggestion } = validationErrorMap[name];
  if (!assertion) {
    throw new StorageError({ name, message, recoverySuggestion });
  }
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/constants.mjs
var LOCAL_TESTING_S3_ENDPOINT = "http://localhost:20005";
var DEFAULT_ACCESS_LEVEL = "guest";
var DEFAULT_PRESIGN_EXPIRATION = 900;
var MAX_URL_EXPIRATION = 7 * 24 * 60 * 60 * 1e3;
var MiB = 1024 * 1024;
var GiB = 1024 * MiB;
var TiB = 1024 * GiB;
var DEFAULT_PART_SIZE = 5 * MiB;
var MAX_OBJECT_SIZE = 5 * TiB;
var MAX_PARTS_COUNT = 1e4;
var DEFAULT_QUEUE_SIZE = 4;
var UPLOADS_STORAGE_KEY = "__uploadInProgress";
var STORAGE_INPUT_PREFIX = "prefix";
var STORAGE_INPUT_KEY = "key";
var STORAGE_INPUT_PATH = "path";
var DEFAULT_DELIMITER = "/";
var CHECKSUM_ALGORITHM_CRC32 = "crc-32";

// node_modules/@aws-amplify/storage/dist/esm/utils/logger.mjs
var logger2 = new ConsoleLogger("Storage");

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/transferTask.mjs
var createCancellableTask = ({ job, onCancel }) => {
  const state = "IN_PROGRESS";
  let canceledErrorMessage;
  const cancelableTask = {
    cancel: (message) => {
      const { state: taskState } = cancelableTask;
      if (taskState === "CANCELED" || taskState === "ERROR" || taskState === "SUCCESS") {
        logger2.debug(`This task cannot be canceled. State: ${taskState}`);
        return;
      }
      cancelableTask.state = "CANCELED";
      canceledErrorMessage = message;
      onCancel(canceledErrorMessage);
    },
    state
  };
  const wrappedJobPromise = (async () => {
    try {
      const result = await job();
      cancelableTask.state = "SUCCESS";
      return result;
    } catch (e) {
      if (isCancelError(e)) {
        cancelableTask.state = "CANCELED";
        e.message = canceledErrorMessage ?? e.message;
      }
      cancelableTask.state = "ERROR";
      throw e;
    }
  })();
  return Object.assign(cancelableTask, {
    result: wrappedJobPromise
  });
};
var createDownloadTask = createCancellableTask;
var createUploadTask = ({ job, onCancel, onResume, onPause, isMultipartUpload }) => {
  const cancellableTask = createCancellableTask({
    job,
    onCancel
  });
  const uploadTask = Object.assign(cancellableTask, {
    pause: () => {
      const { state } = uploadTask;
      if (!isMultipartUpload || state !== "IN_PROGRESS") {
        logger2.debug(`This task cannot be paused. State: ${state}`);
        return;
      }
      uploadTask.state = "PAUSED";
      onPause == null ? void 0 : onPause();
    },
    resume: () => {
      const { state } = uploadTask;
      if (!isMultipartUpload || state !== "PAUSED") {
        logger2.debug(`This task cannot be resumed. State: ${state}`);
        return;
      }
      uploadTask.state = "IN_PROGRESS";
      onResume == null ? void 0 : onResume();
    }
  });
  return uploadTask;
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/byteLength.mjs
var byteLength = (input) => {
  if (input === null || input === void 0)
    return 0;
  if (typeof input === "string") {
    const blob = new Blob([input]);
    return blob.size;
  } else if (typeof input.byteLength === "number") {
    return input.byteLength;
  } else if (typeof input.size === "number") {
    return input.size;
  }
  return void 0;
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/md5.mjs
var import_fast_xml_parser = __toESM(require_fast_xml_parser(), 1);

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/runtime/base64/index.browser.mjs
function bytesToBase64(bytes) {
  const base64Str = Array.from(bytes, (x) => String.fromCodePoint(x)).join("");
  return btoa(base64Str);
}
function toBase64(input) {
  if (typeof input === "string") {
    return bytesToBase64(new TextEncoder().encode(input));
  }
  return bytesToBase64(new Uint8Array(input.buffer, input.byteOffset, input.byteLength));
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/readFile.mjs
var readFile = (file) => new Promise((resolve, reject) => {
  const reader = new FileReader();
  reader.onload = () => {
    resolve(reader.result);
  };
  reader.onabort = () => {
    reject(new Error("Read aborted"));
  };
  reader.onerror = () => {
    reject(reader.error);
  };
  reader.readAsArrayBuffer(file);
});

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/md5.mjs
var calculateContentMd5 = async (content) => {
  const hasher = new Md5();
  const buffer = content instanceof Blob ? await readFile(content) : content;
  hasher.update(buffer);
  const digest = await hasher.digest();
  return toBase64(digest);
};

// node_modules/@aws-amplify/storage/dist/esm/utils/resolvePrefix.mjs
var resolvePrefix = ({ accessLevel, targetIdentityId }) => {
  if (accessLevel === "private") {
    assertValidationError(!!targetIdentityId, StorageValidationErrorCode.NoIdentityId);
    return `private/${targetIdentityId}/`;
  } else if (accessLevel === "protected") {
    assertValidationError(!!targetIdentityId, StorageValidationErrorCode.NoIdentityId);
    return `protected/${targetIdentityId}/`;
  } else {
    return "public/";
  }
};

// node_modules/@aws-amplify/storage/dist/esm/errors/constants.mjs
var INVALID_STORAGE_INPUT = "InvalidStorageInput";

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/resolveS3ConfigAndInput.mjs
var resolveS3ConfigAndInput = async (amplify, apiInput) => {
  var _a, _b, _c, _d;
  const { options: apiOptions } = apiInput ?? {};
  const { identityId } = await amplify.Auth.fetchAuthSession();
  const credentialsProvider = async (options) => {
    if (isLocationCredentialsProvider(apiOptions)) {
      assertStorageInput(apiInput);
    }
    const { credentials } = isLocationCredentialsProvider(apiOptions) ? await apiOptions.locationCredentialsProvider(options) : await amplify.Auth.fetchAuthSession();
    assertValidationError(!!credentials, StorageValidationErrorCode.NoCredentials);
    return credentials;
  };
  const { bucket: defaultBucket, region: defaultRegion, dangerouslyConnectToHttpEndpointForTesting, buckets } = ((_b = (_a = amplify.getConfig()) == null ? void 0 : _a.Storage) == null ? void 0 : _b.S3) ?? {};
  const { bucket = defaultBucket, region = defaultRegion } = (apiOptions == null ? void 0 : apiOptions.bucket) && resolveBucketConfig(apiOptions, buckets) || {};
  assertValidationError(!!bucket, StorageValidationErrorCode.NoBucket);
  assertValidationError(!!region, StorageValidationErrorCode.NoRegion);
  const { defaultAccessLevel, prefixResolver = resolvePrefix, isObjectLockEnabled } = ((_d = (_c = amplify.libraryOptions) == null ? void 0 : _c.Storage) == null ? void 0 : _d.S3) ?? {};
  const accessLevel = (apiOptions == null ? void 0 : apiOptions.accessLevel) ?? defaultAccessLevel ?? DEFAULT_ACCESS_LEVEL;
  const targetIdentityId = accessLevel === "protected" ? (apiOptions == null ? void 0 : apiOptions.targetIdentityId) ?? identityId : identityId;
  const keyPrefix = await prefixResolver({ accessLevel, targetIdentityId });
  return {
    s3Config: {
      credentials: credentialsProvider,
      region,
      useAccelerateEndpoint: apiOptions == null ? void 0 : apiOptions.useAccelerateEndpoint,
      ...(apiOptions == null ? void 0 : apiOptions.customEndpoint) ? { customEndpoint: apiOptions.customEndpoint } : {},
      ...dangerouslyConnectToHttpEndpointForTesting ? {
        customEndpoint: LOCAL_TESTING_S3_ENDPOINT,
        forcePathStyle: true
      } : {}
    },
    bucket,
    keyPrefix,
    identityId,
    isObjectLockEnabled
  };
};
var isLocationCredentialsProvider = (options) => {
  return !!(options == null ? void 0 : options.locationCredentialsProvider);
};
var isInputWithCallbackPath = (input) => {
  var _a, _b, _c, _d;
  return (input == null ? void 0 : input.path) && typeof input.path === "function" || ((_a = input == null ? void 0 : input.destination) == null ? void 0 : _a.path) && typeof ((_b = input.destination) == null ? void 0 : _b.path) === "function" || ((_c = input == null ? void 0 : input.source) == null ? void 0 : _c.path) && typeof ((_d = input.source) == null ? void 0 : _d.path) === "function";
};
var isDeprecatedInput = (input) => {
  return isInputWithKey(input) || isInputWithPrefix(input) || isInputWithCopySourceOrDestination(input);
};
var assertStorageInput = (input) => {
  if (isDeprecatedInput(input) || isInputWithCallbackPath(input)) {
    throw new StorageError({
      name: INVALID_STORAGE_INPUT,
      message: "The input needs to have a path as a string value.",
      recoverySuggestion: "Please provide a valid path as a string value for the input."
    });
  }
};
var isInputWithKey = (input) => {
  return !!(typeof input.key === "string");
};
var isInputWithPrefix = (input) => {
  return !!(typeof input.prefix === "string");
};
var isInputWithCopySourceOrDestination = (input) => {
  var _a, _b;
  return !!(typeof ((_a = input.source) == null ? void 0 : _a.key) === "string" || typeof ((_b = input.destination) == null ? void 0 : _b.key) === "string");
};
var resolveBucketConfig = (apiOptions, buckets) => {
  if (typeof apiOptions.bucket === "string") {
    const bucketConfig = buckets == null ? void 0 : buckets[apiOptions.bucket];
    assertValidationError(!!bucketConfig, StorageValidationErrorCode.InvalidStorageBucket);
    return { bucket: bucketConfig.bucketName, region: bucketConfig.region };
  }
  if (typeof apiOptions.bucket === "object") {
    return {
      bucket: apiOptions.bucket.bucketName,
      region: apiOptions.bucket.region
    };
  }
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/validateBucketOwnerID.mjs
var VALID_AWS_ACCOUNT_ID_PATTERN = /^\d{12}/;
var validateBucketOwnerID = (accountID) => {
  if (accountID === void 0) {
    return;
  }
  assertValidationError(VALID_AWS_ACCOUNT_ID_PATTERN.test(accountID), StorageValidationErrorCode.InvalidAWSAccountID);
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/isInputWithPath.mjs
var isInputWithPath = (input) => {
  return input.path !== void 0;
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/resolveIdentityId.mjs
var resolveIdentityId = (identityId) => {
  assertValidationError(!!identityId, StorageValidationErrorCode.NoIdentityId);
  return identityId;
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/validateStorageOperationInput.mjs
var validateStorageOperationInput = (input, identityId) => {
  assertValidationError(
    // Key present without a path
    !!input.key && !input.path || // Path present without a key
    !input.key && !!input.path,
    StorageValidationErrorCode.InvalidStorageOperationInput
  );
  if (isInputWithPath(input)) {
    const { path } = input;
    const objectKey = typeof path === "string" ? path : path({ identityId: resolveIdentityId(identityId) });
    assertValidationError(!objectKey.startsWith("/"), StorageValidationErrorCode.InvalidStoragePathInput);
    return {
      inputType: STORAGE_INPUT_PATH,
      objectKey
    };
  } else {
    return { inputType: STORAGE_INPUT_KEY, objectKey: input.key };
  }
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/runtime/xmlParser/dom.mjs
var parser = {
  parse: (xmlStr) => {
    const domParser = new DOMParser();
    const xml = domParser.parseFromString(xmlStr, "text/xml");
    const parsedObj = parseXmlNode(xml);
    const rootKey = Object.keys(parsedObj)[0];
    return parsedObj[rootKey];
  }
};
var parseXmlNode = (node) => {
  var _a;
  if (isDocumentNode(node)) {
    return {
      [node.documentElement.nodeName]: parseXmlNode(node.documentElement)
    };
  }
  if (node.nodeType === Node.TEXT_NODE) {
    return (_a = node.nodeValue) == null ? void 0 : _a.trim();
  }
  if (isElementNode(node)) {
    if (isTextOnlyElementNode(node)) {
      return node.childNodes[0].nodeValue;
    }
    const nodeValue = {};
    for (const attr of node.attributes) {
      if (!isNamespaceAttributeName(attr.nodeName)) {
        nodeValue[attr.nodeName] = attr.nodeValue;
      }
    }
    if (node.children.length > 0) {
      for (const child of node.children) {
        const childValue = parseXmlNode(child);
        if (childValue === void 0) {
          continue;
        }
        const childName = child.nodeName;
        if (nodeValue[childName] === void 0) {
          nodeValue[childName] = childValue;
        } else if (Array.isArray(nodeValue[childName])) {
          nodeValue[childName].push(childValue);
        } else {
          nodeValue[childName] = [nodeValue[childName], childValue];
        }
      }
    }
    return Object.keys(nodeValue).length === 0 ? "" : nodeValue;
  }
};
var isElementNode = (node) => node.nodeType === Node.ELEMENT_NODE;
var isDocumentNode = (node) => node.nodeType === Node.DOCUMENT_NODE;
var isTextOnlyElementNode = (node) => {
  var _a;
  return hasOnlyNamespaceAttributes(node) && node.children.length === 0 && ((_a = node.firstChild) == null ? void 0 : _a.nodeType) === Node.TEXT_NODE;
};
var hasOnlyNamespaceAttributes = (node) => {
  for (const attr of node.attributes) {
    if (!isNamespaceAttributeName(attr.nodeName)) {
      return false;
    }
  }
  return true;
};
var isNamespaceAttributeName = (name) => name === "xmlns" || name.startsWith("xmlns:");

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/utils/parsePayload.mjs
var import_buffer = __toESM(require_buffer(), 1);
var createXmlErrorParser = ({ noErrorWrapping = false } = {}) => async (response) => {
  if (!response || response.statusCode < 300) {
    return;
  }
  const { statusCode } = response;
  const body = await parseXmlBody(response);
  const errorLocation = noErrorWrapping ? body : body.Error;
  const code = (errorLocation == null ? void 0 : errorLocation.Code) ? errorLocation.Code : statusCode === 404 ? "NotFound" : statusCode.toString();
  const message = (errorLocation == null ? void 0 : errorLocation.message) ?? (errorLocation == null ? void 0 : errorLocation.Message) ?? code;
  const error = new Error(message);
  return Object.assign(error, {
    name: code,
    $metadata: parseMetadata(response)
  });
};
var parseXmlBody = async (response) => {
  if (!response.body) {
    throw new Error("S3 aborted request.");
  }
  const data = await response.body.text();
  if ((data == null ? void 0 : data.length) > 0) {
    try {
      return parser.parse(data);
    } catch (error) {
      throw new Error(`Failed to parse XML response: ${error}`);
    }
  }
  return {};
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/base.mjs
var import_fast_xml_parser2 = __toESM(require_fast_xml_parser(), 1);
var import_buffer2 = __toESM(require_buffer(), 1);

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/utils/createRetryDecider.mjs
var createRetryDecider = (errorParser) => async (response, error, middlewareContext) => {
  const defaultRetryDecider = getRetryDecider(errorParser);
  const defaultRetryDecision = await defaultRetryDecider(response, error);
  if (!response) {
    return { retryable: defaultRetryDecision.retryable };
  }
  const parsedError = await errorParser(response);
  const errorCode = parsedError == null ? void 0 : parsedError.name;
  const errorMessage = parsedError == null ? void 0 : parsedError.message;
  const isCredentialsExpired = isCredentialsExpiredError(errorCode, errorMessage);
  return {
    retryable: defaultRetryDecision.retryable || // If we know the previous retry attempt sets isCredentialsExpired in the
    // middleware context, we don't want to retry anymore.
    !!(isCredentialsExpired && !(middlewareContext == null ? void 0 : middlewareContext.isCredentialsExpired)),
    isCredentialsExpiredError: isCredentialsExpired
  };
};
var INVALID_TOKEN_ERROR_CODES = [
  "RequestExpired",
  "ExpiredTokenException",
  "ExpiredToken"
];
var isCredentialsExpiredError = (errorCode, errorMessage) => {
  const isExpiredTokenError = !!errorCode && INVALID_TOKEN_ERROR_CODES.includes(errorCode);
  const isExpiredSignatureError = !!errorCode && !!errorMessage && errorCode.includes("Signature") && errorMessage.includes("expired");
  return isExpiredTokenError || isExpiredSignatureError;
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/base.mjs
var DOMAIN_PATTERN = /^[a-z0-9][a-z0-9.-]{1,61}[a-z0-9]$/;
var IP_ADDRESS_PATTERN = /(\d+\.){3}\d+/;
var DOTS_PATTERN = /\.\./;
var SERVICE_NAME = "s3";
var endpointResolver = (options, apiInput) => {
  const { region, useAccelerateEndpoint, customEndpoint, forcePathStyle } = options;
  let endpoint;
  if (customEndpoint) {
    if (customEndpoint === LOCAL_TESTING_S3_ENDPOINT) {
      endpoint = new AmplifyUrl(customEndpoint);
    }
    assertValidationError(!customEndpoint.includes("://"), StorageValidationErrorCode.InvalidCustomEndpoint);
    endpoint = new AmplifyUrl(`https://${customEndpoint}`);
  } else if (useAccelerateEndpoint) {
    assertValidationError(!forcePathStyle, StorageValidationErrorCode.ForcePathStyleEndpointNotSupported);
    endpoint = new AmplifyUrl(`https://s3-accelerate.${getDnsSuffix(region)}`);
  } else {
    endpoint = new AmplifyUrl(`https://s3.${region}.${getDnsSuffix(region)}`);
  }
  if (apiInput == null ? void 0 : apiInput.Bucket) {
    assertValidationError(isDnsCompatibleBucketName(apiInput.Bucket), StorageValidationErrorCode.DnsIncompatibleBucketName);
    if (forcePathStyle || apiInput.Bucket.includes(".")) {
      endpoint.pathname = `/${apiInput.Bucket}`;
    } else {
      endpoint.host = `${apiInput.Bucket}.${endpoint.host}`;
    }
  }
  return { url: endpoint };
};
var isDnsCompatibleBucketName = (bucketName) => DOMAIN_PATTERN.test(bucketName) && !IP_ADDRESS_PATTERN.test(bucketName) && !DOTS_PATTERN.test(bucketName);
var parseXmlError = createXmlErrorParser({ noErrorWrapping: true });
var retryDecider = createRetryDecider(parseXmlError);
var defaultConfig = {
  service: SERVICE_NAME,
  endpointResolver,
  retryDecider,
  computeDelay: jitteredBackoff,
  userAgentValue: getAmplifyUserAgent(),
  useAccelerateEndpoint: false,
  uriEscapePath: false
  // Required by S3. See https://github.com/aws/aws-sdk-js-v3/blob/9ba012dfa3a3429aa2db0f90b3b0b3a7a31f9bc3/packages/signature-v4/src/SignatureV4.ts#L76-L83
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/getObject.mjs
var import_fast_xml_parser3 = __toESM(require_fast_xml_parser(), 1);
var import_buffer3 = __toESM(require_buffer(), 1);

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/utils/deserializeHelpers.mjs
var map = (obj, instructions) => {
  const result = {};
  for (const [key, instruction] of Object.entries(instructions)) {
    const [accessor, deserializer] = Array.isArray(instruction) ? instruction : [instruction];
    if (Object.prototype.hasOwnProperty.call(obj, accessor)) {
      result[key] = deserializer ? deserializer(obj[accessor]) : String(obj[accessor]);
    }
  }
  return result;
};
var deserializeNumber = (value) => value ? Number(value) : void 0;
var deserializeBoolean = (value) => {
  return value ? value === "true" : void 0;
};
var deserializeTimestamp = (value) => {
  return value ? new Date(value) : void 0;
};
var deserializeStringTag = (value) => String(value);
var emptyArrayGuard = (value, deserializer) => {
  if (value === "") {
    return [];
  }
  const valueArray = (Array.isArray(value) ? value : [value]).filter((e) => e != null);
  return deserializer(valueArray);
};
var deserializeMetadata = (headers) => {
  const objectMetadataHeaderPrefix = "x-amz-meta-";
  const deserialized = Object.keys(headers).filter((header) => header.startsWith(objectMetadataHeaderPrefix)).reduce((acc, header) => {
    acc[header.replace(objectMetadataHeaderPrefix, "")] = headers[header];
    return acc;
  }, {});
  return Object.keys(deserialized).length > 0 ? deserialized : void 0;
};
var buildStorageServiceError = (error) => new StorageError({
  name: error.name,
  message: error.message,
  metadata: error.$metadata
});
var deserializeCompletedPartList = (input) => input.map((item) => map(item, {
  PartNumber: ["PartNumber", deserializeNumber],
  ETag: "ETag",
  ChecksumCRC32: "ChecksumCRC32"
}));

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/utils/serializeHelpers.mjs
var assignStringVariables = (values) => {
  const queryParams = {};
  for (const [key, value] of Object.entries(values)) {
    if (value != null) {
      queryParams[key] = value.toString();
    }
  }
  return queryParams;
};
var serializeObjectConfigsToHeaders = async (input) => {
  var _a;
  return {
    ...assignStringVariables({
      "x-amz-acl": input.ACL,
      "cache-control": input.CacheControl,
      "content-disposition": input.ContentDisposition,
      "content-language": input.ContentLanguage,
      "content-encoding": input.ContentEncoding,
      "content-type": input.ContentType,
      expires: (_a = input.Expires) == null ? void 0 : _a.toUTCString(),
      "x-amz-tagging": input.Tagging,
      ...serializeMetadata(input.Metadata)
    })
  };
};
var serializeMetadata = (metadata = {}) => Object.keys(metadata).reduce((acc, suffix) => {
  acc[`x-amz-meta-${suffix.toLowerCase()}`] = metadata[suffix];
  return acc;
}, {});
var serializePathnameObjectKey = (url, key) => {
  return url.pathname.replace(/\/$/, "") + `/${key.split("/").map(extendedEncodeURIComponent).join("/")}`;
};
function validateS3RequiredParameter(assertion, paramName) {
  if (!assertion) {
    throw new StorageError({
      name: AmplifyErrorCode.Unknown,
      message: "An unknown error has occurred.",
      underlyingError: new TypeError(`Expected a non-null value for S3 parameter ${paramName}`),
      recoverySuggestion: "This is likely to be a bug. Please reach out to library authors."
    });
  }
}

// node_modules/@aws-amplify/storage/dist/esm/errors/IntegrityError.mjs
var IntegrityError = class _IntegrityError extends StorageError {
  constructor(params) {
    super({
      name: AmplifyErrorCode.Unknown,
      message: "An unknown error has occurred.",
      recoverySuggestion: "This may be a bug. Please reach out to library authors.",
      metadata: params == null ? void 0 : params.metadata
    });
    this.constructor = _IntegrityError;
    Object.setPrototypeOf(this, _IntegrityError.prototype);
  }
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/validateObjectUrl.mjs
function validateObjectUrl({ bucketName, key, objectURL }) {
  if (!bucketName || !key || !objectURL) {
    throw new IntegrityError();
  }
  const bucketWithDots = bucketName.includes(".");
  const encodedBucketName = extendedEncodeURIComponent(bucketName);
  const encodedKey = key.split("/").map(extendedEncodeURIComponent).join("/");
  const isPathStyleUrl = objectURL.pathname === `/${encodedBucketName}/${encodedKey}`;
  const isSubdomainUrl = objectURL.hostname.startsWith(`${encodedBucketName}.`) && objectURL.pathname === `/${encodedKey}`;
  if (!(isPathStyleUrl || !bucketWithDots && isSubdomainUrl)) {
    throw new IntegrityError();
  }
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/getObject.mjs
var USER_AGENT_HEADER = "x-amz-user-agent";
var getObjectSerializer = async (input, endpoint) => {
  const url = new AmplifyUrl(endpoint.url.toString());
  validateS3RequiredParameter(!!input.Key, "Key");
  url.pathname = serializePathnameObjectKey(url, input.Key);
  url.search = new AmplifyUrlSearchParams({
    "x-id": "GetObject"
  }).toString();
  validateObjectUrl({
    bucketName: input.Bucket,
    key: input.Key,
    objectURL: url
  });
  return {
    method: "GET",
    headers: {
      ...input.Range && { Range: input.Range },
      ...assignStringVariables({
        "x-amz-expected-bucket-owner": input.ExpectedBucketOwner
      })
    },
    url
  };
};
var getObjectDeserializer = async (response) => {
  if (response.statusCode >= 300) {
    throw buildStorageServiceError(await parseXmlError(response));
  } else {
    return {
      ...map(response.headers, {
        DeleteMarker: ["x-amz-delete-marker", deserializeBoolean],
        AcceptRanges: "accept-ranges",
        Expiration: "x-amz-expiration",
        Restore: "x-amz-restore",
        LastModified: ["last-modified", deserializeTimestamp],
        ContentLength: ["content-length", deserializeNumber],
        ETag: "etag",
        ChecksumCRC32: "x-amz-checksum-crc32",
        ChecksumCRC32C: "x-amz-checksum-crc32c",
        ChecksumSHA1: "x-amz-checksum-sha1",
        ChecksumSHA256: "x-amz-checksum-sha256",
        ChecksumType: "x-amz-checksum-type",
        MissingMeta: ["x-amz-missing-meta", deserializeNumber],
        VersionId: "x-amz-version-id",
        CacheControl: "cache-control",
        ContentDisposition: "content-disposition",
        ContentEncoding: "content-encoding",
        ContentLanguage: "content-language",
        ContentRange: "content-range",
        ContentType: "content-type",
        Expires: ["expires", deserializeTimestamp],
        WebsiteRedirectLocation: "x-amz-website-redirect-location",
        ServerSideEncryption: "x-amz-server-side-encryption",
        SSECustomerAlgorithm: "x-amz-server-side-encryption-customer-algorithm",
        SSECustomerKeyMD5: "x-amz-server-side-encryption-customer-key-md5",
        SSEKMSKeyId: "x-amz-server-side-encryption-aws-kms-key-id",
        BucketKeyEnabled: [
          "x-amz-server-side-encryption-bucket-key-enabled",
          deserializeBoolean
        ],
        StorageClass: "x-amz-storage-class",
        RequestCharged: "x-amz-request-charged",
        ReplicationStatus: "x-amz-replication-status",
        PartsCount: ["x-amz-mp-parts-count", deserializeNumber],
        TagCount: ["x-amz-tagging-count", deserializeNumber],
        ObjectLockMode: "x-amz-object-lock-mode",
        ObjectLockRetainUntilDate: [
          "x-amz-object-lock-retain-until-date",
          deserializeTimestamp
        ],
        ObjectLockLegalHoldStatus: "x-amz-object-lock-legal-hold"
      }),
      Metadata: deserializeMetadata(response.headers),
      $metadata: parseMetadata(response),
      // @ts-expect-error The body is a CompatibleHttpResponse type because the lower-level handler is XHR instead of
      // fetch, which represents payload in Blob instread of ReadableStream.
      Body: response.body
    };
  }
};
var getObject = composeServiceApi(s3TransferHandler, getObjectSerializer, getObjectDeserializer, { ...defaultConfig, responseType: "blob" });
var getPresignedGetObjectUrl = async (config, input) => {
  const endpoint = defaultConfig.endpointResolver(config, input);
  const { url, headers, method } = await getObjectSerializer(input, endpoint);
  url.searchParams.append(CONTENT_SHA256_HEADER, EMPTY_HASH);
  if (config.userAgentValue) {
    url.searchParams.append(config.userAgentHeader ?? USER_AGENT_HEADER, config.userAgentValue);
  }
  if (input.ResponseContentType) {
    url.searchParams.append("response-content-type", input.ResponseContentType);
  }
  if (input.ResponseContentDisposition) {
    url.searchParams.append("response-content-disposition", input.ResponseContentDisposition);
  }
  for (const [headerName, value] of Object.entries(headers).sort(([key1], [key2]) => key1.localeCompare(key2))) {
    url.searchParams.append(headerName, value);
  }
  return presignUrl({ method, url, body: void 0 }, {
    signingService: defaultConfig.service,
    signingRegion: config.region,
    ...defaultConfig,
    ...config
  });
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/listObjectsV2.mjs
var import_fast_xml_parser4 = __toESM(require_fast_xml_parser(), 1);
var import_buffer4 = __toESM(require_buffer(), 1);
var listObjectsV2Serializer = (input, endpoint) => {
  const headers = assignStringVariables({
    "x-amz-request-payer": input.RequestPayer,
    "x-amz-expected-bucket-owner": input.ExpectedBucketOwner
  });
  const query = assignStringVariables({
    "list-type": "2",
    "continuation-token": input.ContinuationToken,
    delimiter: input.Delimiter,
    "encoding-type": input.EncodingType,
    "fetch-owner": input.FetchOwner,
    "max-keys": input.MaxKeys,
    prefix: input.Prefix,
    "start-after": input.StartAfter
  });
  const url = new AmplifyUrl(endpoint.url.toString());
  url.search = new AmplifyUrlSearchParams(query).toString();
  return {
    method: "GET",
    headers,
    url
  };
};
var listObjectsV2Deserializer = async (response) => {
  if (response.statusCode >= 300) {
    throw buildStorageServiceError(await parseXmlError(response));
  } else {
    const parsed = await parseXmlBody(response);
    const contents = map(parsed, {
      CommonPrefixes: [
        "CommonPrefixes",
        (value) => emptyArrayGuard(value, deserializeCommonPrefixList)
      ],
      Contents: [
        "Contents",
        (value) => emptyArrayGuard(value, deserializeObjectList)
      ],
      ContinuationToken: "ContinuationToken",
      Delimiter: "Delimiter",
      EncodingType: ["EncodingType", deserializeStringTag],
      IsTruncated: ["IsTruncated", deserializeBoolean],
      KeyCount: ["KeyCount", deserializeNumber],
      MaxKeys: ["MaxKeys", deserializeNumber],
      Name: "Name",
      NextContinuationToken: "NextContinuationToken",
      Prefix: "Prefix",
      StartAfter: "StartAfter"
    });
    const output = {
      $metadata: parseMetadata(response),
      ...contents
    };
    validateCorroboratingElements(output);
    return output;
  }
};
var deserializeCommonPrefixList = (output) => output.map(deserializeCommonPrefix);
var deserializeCommonPrefix = (output) => map(output, {
  Prefix: "Prefix"
});
var deserializeObjectList = (output) => output.map(deserializeObject);
var deserializeObject = (output) => map(output, {
  Key: "Key",
  LastModified: ["LastModified", deserializeTimestamp],
  ETag: "ETag",
  ChecksumAlgorithm: [
    "ChecksumAlgorithm",
    (value) => emptyArrayGuard(value, deserializeChecksumAlgorithmList)
  ],
  ChecksumType: ["ChecksumType", deserializeStringTag],
  Size: ["Size", deserializeNumber],
  StorageClass: ["StorageClass", deserializeStringTag],
  Owner: ["Owner", deserializeOwner]
});
var deserializeChecksumAlgorithmList = (output) => output.map(deserializeStringTag);
var deserializeOwner = (output) => map(output, { DisplayName: "DisplayName", ID: "ID" });
var validateCorroboratingElements = (response) => {
  const { IsTruncated, KeyCount, Contents = [], CommonPrefixes = [], NextContinuationToken } = response;
  const validTruncation = IsTruncated && !!NextContinuationToken || !IsTruncated && !NextContinuationToken;
  const validNumberOfKeysReturned = KeyCount === Contents.length + CommonPrefixes.length;
  if (!validTruncation || !validNumberOfKeysReturned) {
    throw new IntegrityError({ metadata: response.$metadata });
  }
};
var listObjectsV2 = composeServiceApi(s3TransferHandler, listObjectsV2Serializer, listObjectsV2Deserializer, { ...defaultConfig, responseType: "text" });

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/putObject.mjs
var import_fast_xml_parser5 = __toESM(require_fast_xml_parser(), 1);
var import_buffer5 = __toESM(require_buffer(), 1);
var putObjectSerializer = async (input, endpoint) => {
  const headers = {
    ...await serializeObjectConfigsToHeaders({
      ...input,
      ContentType: input.ContentType ?? "application/octet-stream"
    }),
    ...assignStringVariables({
      "content-md5": input.ContentMD5,
      "x-amz-checksum-crc32": input.ChecksumCRC32,
      "x-amz-expected-bucket-owner": input.ExpectedBucketOwner,
      "If-None-Match": input.IfNoneMatch
    })
  };
  const url = new AmplifyUrl(endpoint.url.toString());
  validateS3RequiredParameter(!!input.Key, "Key");
  url.pathname = serializePathnameObjectKey(url, input.Key);
  url.search = new AmplifyUrlSearchParams({
    "x-id": "PutObject"
  }).toString();
  validateObjectUrl({
    bucketName: input.Bucket,
    key: input.Key,
    objectURL: url
  });
  return {
    method: "PUT",
    headers,
    url,
    body: input.Body
  };
};
var putObjectDeserializer = async (response) => {
  if (response.statusCode >= 300) {
    throw buildStorageServiceError(await parseXmlError(response));
  } else {
    return {
      ...map(response.headers, {
        ETag: "etag",
        VersionId: "x-amz-version-id"
      }),
      $metadata: parseMetadata(response)
    };
  }
};
var putObject = composeServiceApi(s3TransferHandler, putObjectSerializer, putObjectDeserializer, { ...defaultConfig, responseType: "text" });

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/createMultipartUpload.mjs
var import_fast_xml_parser6 = __toESM(require_fast_xml_parser(), 1);
var import_buffer6 = __toESM(require_buffer(), 1);
var createMultipartUploadSerializer = async (input, endpoint) => {
  const headers = {
    ...await serializeObjectConfigsToHeaders(input),
    ...assignStringVariables({
      "x-amz-checksum-algorithm": input.ChecksumAlgorithm,
      "x-amz-checksum-type": input.ChecksumType,
      "x-amz-expected-bucket-owner": input.ExpectedBucketOwner
    })
  };
  const url = new AmplifyUrl(endpoint.url.toString());
  validateS3RequiredParameter(!!input.Key, "Key");
  url.pathname = serializePathnameObjectKey(url, input.Key);
  url.search = "uploads";
  validateObjectUrl({
    bucketName: input.Bucket,
    key: input.Key,
    objectURL: url
  });
  return {
    method: "POST",
    headers,
    url
  };
};
var createMultipartUploadDeserializer = async (response) => {
  if (response.statusCode >= 300) {
    throw buildStorageServiceError(await parseXmlError(response));
  } else {
    const parsed = await parseXmlBody(response);
    const contents = map(parsed, {
      UploadId: "UploadId"
    });
    return {
      $metadata: parseMetadata(response),
      ...contents
    };
  }
};
var createMultipartUpload = composeServiceApi(s3TransferHandler, createMultipartUploadSerializer, createMultipartUploadDeserializer, { ...defaultConfig, responseType: "text" });

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/uploadPart.mjs
var import_fast_xml_parser7 = __toESM(require_fast_xml_parser(), 1);
var import_buffer7 = __toESM(require_buffer(), 1);
var uploadPartSerializer = async (input, endpoint) => {
  const headers = {
    ...assignStringVariables({
      "x-amz-checksum-crc32": input.ChecksumCRC32,
      "content-md5": input.ContentMD5,
      "x-amz-expected-bucket-owner": input.ExpectedBucketOwner
    }),
    "content-type": "application/octet-stream"
  };
  const url = new AmplifyUrl(endpoint.url.toString());
  validateS3RequiredParameter(!!input.Key, "Key");
  url.pathname = serializePathnameObjectKey(url, input.Key);
  validateS3RequiredParameter(!!input.PartNumber, "PartNumber");
  validateS3RequiredParameter(!!input.UploadId, "UploadId");
  url.search = new AmplifyUrlSearchParams({
    partNumber: input.PartNumber + "",
    uploadId: input.UploadId
  }).toString();
  validateObjectUrl({
    bucketName: input.Bucket,
    key: input.Key,
    objectURL: url
  });
  return {
    method: "PUT",
    headers,
    url,
    body: input.Body
  };
};
var uploadPartDeserializer = async (response) => {
  if (response.statusCode >= 300) {
    throw buildStorageServiceError(await parseXmlError(response));
  } else {
    return {
      ...map(response.headers, {
        ETag: "etag"
      }),
      $metadata: parseMetadata(response)
    };
  }
};
var uploadPart = composeServiceApi(s3TransferHandler, uploadPartSerializer, uploadPartDeserializer, { ...defaultConfig, responseType: "text" });

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/completeMultipartUpload.mjs
var import_fast_xml_parser8 = __toESM(require_fast_xml_parser(), 1);
var import_buffer9 = __toESM(require_buffer(), 1);

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/validateMultipartUploadXML.mjs
var import_buffer8 = __toESM(require_buffer(), 1);

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/utils/integrityHelpers.mjs
var isNil = (value) => {
  return value === void 0 || value === null;
};
var bothNilOrEqual = (original, output) => {
  return isNil(original) && isNil(output) || original === output;
};
var isObject = (value) => {
  return value != null && typeof value === "object" && !Array.isArray(value);
};
var isEqual = (object, other) => {
  if (Array.isArray(object) && !Array.isArray(other)) {
    return false;
  }
  if (!Array.isArray(object) && Array.isArray(other)) {
    return false;
  }
  if (Array.isArray(object) && Array.isArray(other)) {
    return object.length === other.length && object.every((val, ix) => isEqual(val, other[ix]));
  }
  if (!isObject(object) || !isObject(other)) {
    return object === other;
  }
  const objectKeys = Object.keys(object);
  const otherKeys = Object.keys(other);
  if (objectKeys.length !== otherKeys.length) {
    return false;
  }
  return objectKeys.every((key) => {
    return otherKeys.includes(key) && isEqual(object[key], other[key]);
  });
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/validateMultipartUploadXML.mjs
function validateMultipartUploadXML(input, xml) {
  if (!input.Parts) {
    throw new IntegrityError();
  }
  const parsedXML = parser.parse(xml);
  const mappedCompletedMultipartUpload = map(parsedXML, {
    Parts: [
      "Part",
      (value) => emptyArrayGuard(value, deserializeCompletedPartList)
    ]
  });
  if (!isEqual(input, mappedCompletedMultipartUpload)) {
    throw new IntegrityError();
  }
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/completeMultipartUpload.mjs
var INVALID_PARAMETER_ERROR_MSG = "Invalid parameter for CompleteMultipartUpload API";
var MISSING_ETAG_ERROR_MSG = "ETag missing from multipart upload";
var MISSING_ETAG_ERROR_SUGGESTION = "Please ensure S3 bucket CORS configuration includes ETag as part of its `ExposeHeaders` element";
var completeMultipartUploadSerializer = async (input, endpoint) => {
  const headers = {
    "content-type": "application/xml",
    ...assignStringVariables({
      "x-amz-checksum-crc32": input.ChecksumCRC32,
      "x-amz-checksum-type": input.ChecksumType,
      "x-amz-expected-bucket-owner": input.ExpectedBucketOwner,
      "If-None-Match": input.IfNoneMatch
    })
  };
  const url = new AmplifyUrl(endpoint.url.toString());
  validateS3RequiredParameter(!!input.Key, "Key");
  url.pathname = serializePathnameObjectKey(url, input.Key);
  validateS3RequiredParameter(!!input.UploadId, "UploadId");
  url.search = new AmplifyUrlSearchParams({
    uploadId: input.UploadId
  }).toString();
  validateS3RequiredParameter(!!input.MultipartUpload, "MultipartUpload");
  validateObjectUrl({
    bucketName: input.Bucket,
    key: input.Key,
    objectURL: url
  });
  const xml = serializeCompletedMultipartUpload(input.MultipartUpload);
  validateMultipartUploadXML(input.MultipartUpload, xml);
  return {
    method: "POST",
    headers,
    url,
    body: '<?xml version="1.0" encoding="UTF-8"?>' + xml
  };
};
var serializeCompletedMultipartUpload = (input) => {
  var _a;
  if (!((_a = input.Parts) == null ? void 0 : _a.length)) {
    throw new Error(`${INVALID_PARAMETER_ERROR_MSG}: ${JSON.stringify(input)}`);
  }
  return `<CompleteMultipartUpload xmlns="http://s3.amazonaws.com/doc/2006-03-01/">${input.Parts.map(serializeCompletedPartList).join("")}</CompleteMultipartUpload>`;
};
var serializeCompletedPartList = (input) => {
  if (input.PartNumber == null) {
    throw new Error(`${INVALID_PARAMETER_ERROR_MSG}: ${JSON.stringify(input)}`);
  }
  if (!input.ETag) {
    throw new Error(`${MISSING_ETAG_ERROR_MSG}: ${JSON.stringify(input)}. ${MISSING_ETAG_ERROR_SUGGESTION}`);
  }
  const eTag = `<ETag>${input.ETag}</ETag>`;
  const partNumber = `<PartNumber>${input.PartNumber}</PartNumber>`;
  const checksumCRC32 = input.ChecksumCRC32 ? `<ChecksumCRC32>${input.ChecksumCRC32}</ChecksumCRC32>` : "";
  return `<Part>${eTag}${partNumber}${checksumCRC32}</Part>`;
};
var parseXmlBodyOrThrow = async (response) => {
  const parsed = await parseXmlBody(response);
  if (parsed.Code !== void 0 && parsed.Message !== void 0) {
    const error = await parseXmlError({
      ...response,
      statusCode: 500
      // To workaround the >=300 status code check common to other APIs.
    });
    error.$metadata.httpStatusCode = response.statusCode;
    throw buildStorageServiceError(error);
  }
  return parsed;
};
var completeMultipartUploadDeserializer = async (response) => {
  if (response.statusCode >= 300) {
    throw buildStorageServiceError(await parseXmlError(response));
  } else {
    const parsed = await parseXmlBodyOrThrow(response);
    const contents = map(parsed, {
      ETag: "ETag",
      Key: "Key",
      Location: "Location"
    });
    return {
      $metadata: parseMetadata(response),
      ...contents
    };
  }
};
var retryWhenErrorWith200StatusCode = async (response, error, middlewareContext) => {
  if (!response) {
    return { retryable: false };
  }
  if (response.statusCode === 200) {
    if (!response.body) {
      return { retryable: true };
    }
    const parsed = await parseXmlBody(response);
    if (parsed.Code !== void 0 && parsed.Message !== void 0) {
      return { retryable: true };
    }
    return { retryable: false };
  }
  return retryDecider(response, error, middlewareContext);
};
var completeMultipartUpload = composeServiceApi(s3TransferHandler, completeMultipartUploadSerializer, completeMultipartUploadDeserializer, {
  ...defaultConfig,
  responseType: "text",
  retryDecider: retryWhenErrorWith200StatusCode
});

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/listParts.mjs
var import_fast_xml_parser9 = __toESM(require_fast_xml_parser(), 1);
var import_buffer10 = __toESM(require_buffer(), 1);
var listPartsSerializer = async (input, endpoint) => {
  const headers = {};
  const url = new AmplifyUrl(endpoint.url.toString());
  validateS3RequiredParameter(!!input.Key, "Key");
  url.pathname = serializePathnameObjectKey(url, input.Key);
  validateS3RequiredParameter(!!input.UploadId, "UploadId");
  url.search = new AmplifyUrlSearchParams({
    "x-id": "ListParts",
    uploadId: input.UploadId
  }).toString();
  return {
    method: "GET",
    headers,
    url
  };
};
var listPartsDeserializer = async (response) => {
  if (response.statusCode >= 300) {
    throw buildStorageServiceError(await parseXmlError(response));
  } else {
    const parsed = await parseXmlBody(response);
    const contents = map(parsed, {
      UploadId: "UploadId",
      Parts: [
        "Part",
        (value) => emptyArrayGuard(value, deserializeCompletedPartList)
      ]
    });
    return {
      $metadata: parseMetadata(response),
      ...contents
    };
  }
};
var listParts = composeServiceApi(s3TransferHandler, listPartsSerializer, listPartsDeserializer, { ...defaultConfig, responseType: "text" });

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/abortMultipartUpload.mjs
var import_fast_xml_parser10 = __toESM(require_fast_xml_parser(), 1);
var import_buffer11 = __toESM(require_buffer(), 1);
var abortMultipartUploadSerializer = (input, endpoint) => {
  const url = new AmplifyUrl(endpoint.url.toString());
  validateS3RequiredParameter(!!input.Key, "Key");
  url.pathname = serializePathnameObjectKey(url, input.Key);
  validateS3RequiredParameter(!!input.UploadId, "UploadId");
  url.search = new AmplifyUrlSearchParams({
    "x-id": "AbortMultipartUpload",
    uploadId: input.UploadId
  }).toString();
  validateObjectUrl({
    bucketName: input.Bucket,
    key: input.Key,
    objectURL: url
  });
  const headers = {
    ...assignStringVariables({
      "x-amz-expected-bucket-owner": input.ExpectedBucketOwner
    })
  };
  return {
    method: "DELETE",
    headers,
    url
  };
};
var abortMultipartUploadDeserializer = async (response) => {
  if (response.statusCode >= 300) {
    throw buildStorageServiceError(await parseXmlError(response));
  } else {
    return {
      $metadata: parseMetadata(response)
    };
  }
};
var abortMultipartUpload = composeServiceApi(s3TransferHandler, abortMultipartUploadSerializer, abortMultipartUploadDeserializer, { ...defaultConfig, responseType: "text" });

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/copyObject.mjs
var import_fast_xml_parser11 = __toESM(require_fast_xml_parser(), 1);
var import_buffer12 = __toESM(require_buffer(), 1);
var copyObjectSerializer = async (input, endpoint) => {
  var _a;
  const headers = {
    ...await serializeObjectConfigsToHeaders(input),
    ...assignStringVariables({
      "x-amz-copy-source": input.CopySource,
      "x-amz-metadata-directive": input.MetadataDirective,
      "x-amz-copy-source-if-match": input.CopySourceIfMatch,
      "x-amz-copy-source-if-unmodified-since": (_a = input.CopySourceIfUnmodifiedSince) == null ? void 0 : _a.toUTCString(),
      "x-amz-source-expected-bucket-owner": input.ExpectedSourceBucketOwner,
      "x-amz-expected-bucket-owner": input.ExpectedBucketOwner
    })
  };
  validateCopyObjectHeaders(input, headers);
  const url = new AmplifyUrl(endpoint.url.toString());
  validateS3RequiredParameter(!!input.Key, "Key");
  url.pathname = serializePathnameObjectKey(url, input.Key);
  url.search = new AmplifyUrlSearchParams({
    "x-id": "CopyObject"
  }).toString();
  validateObjectUrl({
    bucketName: input.Bucket,
    key: input.Key,
    objectURL: url
  });
  return {
    method: "PUT",
    headers,
    url
  };
};
var validateCopyObjectHeaders = (input, headers) => {
  var _a;
  const validations = [
    headers["x-amz-copy-source"] === input.CopySource,
    bothNilOrEqual(input.MetadataDirective, headers["x-amz-metadata-directive"]),
    bothNilOrEqual(input.CopySourceIfMatch, headers["x-amz-copy-source-if-match"]),
    bothNilOrEqual((_a = input.CopySourceIfUnmodifiedSince) == null ? void 0 : _a.toUTCString(), headers["x-amz-copy-source-if-unmodified-since"])
  ];
  if (validations.some((validation) => !validation)) {
    throw new IntegrityError();
  }
};
var copyObjectDeserializer = async (response) => {
  if (response.statusCode >= 300) {
    throw buildStorageServiceError(await parseXmlError(response));
  } else {
    await parseXmlBody(response);
    return {
      $metadata: parseMetadata(response)
    };
  }
};
var copyObject = composeServiceApi(s3TransferHandler, copyObjectSerializer, copyObjectDeserializer, { ...defaultConfig, responseType: "text" });

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/headObject.mjs
var import_fast_xml_parser12 = __toESM(require_fast_xml_parser(), 1);
var import_buffer13 = __toESM(require_buffer(), 1);
var headObjectSerializer = async (input, endpoint) => {
  const url = new AmplifyUrl(endpoint.url.toString());
  validateS3RequiredParameter(!!input.Key, "Key");
  url.pathname = serializePathnameObjectKey(url, input.Key);
  validateObjectUrl({
    bucketName: input.Bucket,
    key: input.Key,
    objectURL: url
  });
  const headers = assignStringVariables({
    "x-amz-expected-bucket-owner": input.ExpectedBucketOwner
  });
  return {
    method: "HEAD",
    headers,
    url
  };
};
var headObjectDeserializer = async (response) => {
  if (response.statusCode >= 300) {
    throw buildStorageServiceError(await parseXmlError(response));
  } else {
    const contents = {
      ...map(response.headers, {
        ContentLength: ["content-length", deserializeNumber],
        ContentType: "content-type",
        ETag: "etag",
        LastModified: ["last-modified", deserializeTimestamp],
        VersionId: "x-amz-version-id"
      }),
      Metadata: deserializeMetadata(response.headers)
    };
    return {
      $metadata: parseMetadata(response),
      ...contents
    };
  }
};
var headObject = composeServiceApi(s3TransferHandler, headObjectSerializer, headObjectDeserializer, { ...defaultConfig, responseType: "text" });

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/client/s3data/deleteObject.mjs
var import_fast_xml_parser13 = __toESM(require_fast_xml_parser(), 1);
var import_buffer14 = __toESM(require_buffer(), 1);
var deleteObjectSerializer = (input, endpoint) => {
  const url = new AmplifyUrl(endpoint.url.toString());
  validateS3RequiredParameter(!!input.Key, "Key");
  url.pathname = serializePathnameObjectKey(url, input.Key);
  url.search = new AmplifyUrlSearchParams({
    "x-id": "DeleteObject"
  }).toString();
  validateObjectUrl({
    bucketName: input.Bucket,
    key: input.Key,
    objectURL: url
  });
  const headers = assignStringVariables({
    "x-amz-expected-bucket-owner": input.ExpectedBucketOwner
  });
  return {
    method: "DELETE",
    headers,
    url
  };
};
var deleteObjectDeserializer = async (response) => {
  if (response.statusCode >= 300) {
    throw buildStorageServiceError(await parseXmlError(response));
  } else {
    const content = map(response.headers, {
      DeleteMarker: ["x-amz-delete-marker", deserializeBoolean],
      VersionId: "x-amz-version-id",
      RequestCharged: [
        "x-amz-request-charged",
        deserializeStringTag
      ]
    });
    return {
      ...content,
      $metadata: parseMetadata(response)
    };
  }
};
var deleteObject = composeServiceApi(s3TransferHandler, deleteObjectSerializer, deleteObjectDeserializer, { ...defaultConfig, responseType: "text" });

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/userAgent.mjs
function getStorageUserAgentValue(action) {
  return getAmplifyUserAgent({
    category: Category.Storage,
    action
  });
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/crc32.mjs
var import_crc_32 = __toESM(require_crc32(), 1);

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/hexUtils.mjs
var import_fast_xml_parser14 = __toESM(require_fast_xml_parser(), 1);
var hexToUint8Array = (hexString) => new Uint8Array((hexString.match(/\w{2}/g) ?? []).map((h) => parseInt(h, 16)));
var hexToBase64 = (hexString) => toBase64(hexToUint8Array(hexString));

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/crc32.mjs
var CHUNK_SIZE = 1024 * 1024;
var calculateContentCRC32 = async (content, seed = 0) => {
  let internalSeed = seed;
  if (content instanceof ArrayBuffer || ArrayBuffer.isView(content)) {
    let uint8Array;
    if (content instanceof ArrayBuffer) {
      uint8Array = new Uint8Array(content);
    } else {
      uint8Array = new Uint8Array(content.buffer, content.byteOffset, content.byteLength);
    }
    let offset = 0;
    while (offset < uint8Array.length) {
      const end = Math.min(offset + CHUNK_SIZE, uint8Array.length);
      const chunk = uint8Array.slice(offset, end);
      internalSeed = import_crc_32.default.buf(chunk, internalSeed) >>> 0;
      offset = end;
    }
  } else {
    let blob;
    if (content instanceof Blob) {
      blob = content;
    } else {
      blob = new Blob([content]);
    }
    let offset = 0;
    while (offset < blob.size) {
      const end = Math.min(offset + CHUNK_SIZE, blob.size);
      const chunk = blob.slice(offset, end);
      const arrayBuffer = await readFile(chunk);
      const uint8Array = new Uint8Array(arrayBuffer);
      internalSeed = import_crc_32.default.buf(uint8Array, internalSeed) >>> 0;
      offset = end;
    }
  }
  const hex = internalSeed.toString(16).padStart(8, "0");
  return hexToBase64(hex);
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/constructContentDisposition.mjs
var constructContentDisposition = (contentDisposition) => {
  if (!contentDisposition)
    return void 0;
  if (typeof contentDisposition === "string")
    return contentDisposition;
  const { type, filename } = contentDisposition;
  return filename !== void 0 ? `${type}; filename="${filename}"` : type;
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/putObjectJob.mjs
var putObjectJob = (uploadDataInput, abortSignal, totalLength) => async () => {
  const { options: uploadDataOptions, data } = uploadDataInput;
  const { bucket, keyPrefix, s3Config, isObjectLockEnabled, identityId } = await resolveS3ConfigAndInput(Amplify, uploadDataInput);
  const { inputType, objectKey } = validateStorageOperationInput(uploadDataInput, identityId);
  validateBucketOwnerID(uploadDataOptions == null ? void 0 : uploadDataOptions.expectedBucketOwner);
  const finalKey = inputType === STORAGE_INPUT_KEY ? keyPrefix + objectKey : objectKey;
  const { contentDisposition, contentEncoding, contentType = "application/octet-stream", preventOverwrite, metadata, checksumAlgorithm, onProgress, expectedBucketOwner } = uploadDataOptions ?? {};
  const checksumCRC32 = checksumAlgorithm === CHECKSUM_ALGORITHM_CRC32 ? await calculateContentCRC32(data) : void 0;
  const contentMD5 = (
    // check if checksum exists. ex: should not exist in react native
    !checksumCRC32 && isObjectLockEnabled ? await calculateContentMd5(data) : void 0
  );
  const { ETag: eTag, VersionId: versionId } = await putObject({
    ...s3Config,
    abortSignal,
    onUploadProgress: onProgress,
    userAgentValue: getStorageUserAgentValue(StorageAction.UploadData)
  }, {
    Bucket: bucket,
    Key: finalKey,
    Body: data,
    ContentType: contentType,
    ContentDisposition: constructContentDisposition(contentDisposition),
    ContentEncoding: contentEncoding,
    Metadata: metadata,
    ContentMD5: contentMD5,
    ChecksumCRC32: checksumCRC32,
    ExpectedBucketOwner: expectedBucketOwner,
    IfNoneMatch: preventOverwrite ? "*" : void 0
  });
  const result = {
    eTag,
    versionId,
    contentType,
    metadata,
    size: totalLength
  };
  return inputType === STORAGE_INPUT_KEY ? { key: objectKey, ...result } : { path: objectKey, ...result };
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/multipart/uploadHandlers.mjs
var import_fast_xml_parser15 = __toESM(require_fast_xml_parser(), 1);
var import_buffer15 = __toESM(require_buffer(), 1);

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/multipart/uploadPartExecutor.mjs
var uploadPartExecutor = async ({ dataChunkerGenerator, completedPartNumberSet, s3Config, abortSignal, bucket, finalKey, uploadId, onPartUploadCompletion, onProgress, isObjectLockEnabled, useCRC32Checksum, expectedBucketOwner }) => {
  let transferredBytes = 0;
  for (const { data, partNumber, size } of dataChunkerGenerator) {
    if (abortSignal.aborted) {
      logger2.debug("upload executor aborted.");
      break;
    }
    if (completedPartNumberSet.has(partNumber)) {
      logger2.debug(`part ${partNumber} already uploaded.`);
      transferredBytes += size;
      onProgress == null ? void 0 : onProgress({
        transferredBytes
      });
    } else {
      let checksumCRC32;
      if (useCRC32Checksum) {
        checksumCRC32 = await calculateContentCRC32(data);
      }
      const contentMD5 = (
        // check if checksum exists. ex: should not exist in react native
        !checksumCRC32 && isObjectLockEnabled ? await calculateContentMd5(data) : void 0
      );
      const { ETag: eTag } = await uploadPart({
        ...s3Config,
        abortSignal,
        onUploadProgress: (event) => {
          const { transferredBytes: currentPartTransferredBytes } = event;
          onProgress == null ? void 0 : onProgress({
            transferredBytes: transferredBytes + currentPartTransferredBytes
          });
        }
      }, {
        Bucket: bucket,
        Key: finalKey,
        UploadId: uploadId,
        Body: data,
        PartNumber: partNumber,
        ChecksumCRC32: checksumCRC32,
        ContentMD5: contentMD5,
        ExpectedBucketOwner: expectedBucketOwner
      });
      transferredBytes += size;
      onPartUploadCompletion(partNumber, eTag, checksumCRC32);
    }
  }
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/multipart/uploadCache.mjs
var ONE_HOUR = 1e3 * 60 * 60;
var findCachedUploadPartsAndEvictExpired = async ({ resumableUploadsCache, cacheKey, s3Config, bucket, finalKey }) => {
  const allCachedUploads = await listCachedUploadTasks(resumableUploadsCache);
  const validCachedUploads = Object.fromEntries(Object.entries(allCachedUploads).filter(([_, cacheValue]) => cacheValue.lastTouched >= Date.now() - ONE_HOUR));
  if (Object.keys(validCachedUploads).length !== Object.keys(allCachedUploads).length) {
    await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(validCachedUploads));
  }
  if (!validCachedUploads[cacheKey]) {
    return null;
  }
  const cachedUpload = validCachedUploads[cacheKey];
  cachedUpload.lastTouched = Date.now();
  await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(validCachedUploads));
  try {
    const { Parts = [] } = await listParts(s3Config, {
      Bucket: bucket,
      Key: finalKey,
      UploadId: cachedUpload.uploadId
    });
    return {
      parts: Parts,
      uploadId: cachedUpload.uploadId,
      finalCrc32: cachedUpload.finalCrc32
    };
  } catch (e) {
    logger2.debug("failed to list cached parts, removing cached upload.");
    await removeCachedUpload(resumableUploadsCache, cacheKey);
    return null;
  }
};
var listCachedUploadTasks = async (resumableUploadsCache) => {
  try {
    return JSON.parse(await resumableUploadsCache.getItem(UPLOADS_STORAGE_KEY) ?? "{}");
  } catch (e) {
    logger2.debug("failed to parse cached uploads record.");
    return {};
  }
};
var serializeUploadOptions = (options = {}) => {
  const unserializableOptionProperties = [
    "onProgress",
    "resumableUploadsCache",
    // Internally injected implementation not set by customers
    "locationCredentialsProvider"
    // Internally injected implementation not set by customers
  ];
  const serializableOptionEntries = Object.entries(options).filter(([key]) => !unserializableOptionProperties.includes(key));
  if (options.checksumAlgorithm === "crc-32") {
    serializableOptionEntries.push(["checksumType", "FULL_OBJECT"]);
  }
  const serializableOptions = Object.fromEntries(serializableOptionEntries);
  return JSON.stringify(serializableOptions);
};
var getUploadsCacheKey = ({ file, size, contentType, bucket, accessLevel, key, optionsHash }) => {
  let levelStr;
  const resolvedContentType = contentType ?? (file == null ? void 0 : file.type) ?? "application/octet-stream";
  if (accessLevel === void 0) {
    levelStr = "custom";
  } else {
    levelStr = accessLevel === "guest" ? "public" : accessLevel;
  }
  const baseId = `${optionsHash}_${size}_${resolvedContentType}_${bucket}_${levelStr}_${key}`;
  if (file) {
    return `${file.name}_${file.lastModified}_${baseId}`;
  } else {
    return baseId;
  }
};
var cacheMultipartUpload = async (resumableUploadsCache, cacheKey, fileMetadata) => {
  const cachedUploads = await listCachedUploadTasks(resumableUploadsCache);
  cachedUploads[cacheKey] = {
    ...fileMetadata,
    lastTouched: Date.now()
  };
  await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(cachedUploads));
};
var removeCachedUpload = async (resumableUploadsCache, cacheKey) => {
  const cachedUploads = await listCachedUploadTasks(resumableUploadsCache);
  delete cachedUploads[cacheKey];
  await resumableUploadsCache.setItem(UPLOADS_STORAGE_KEY, JSON.stringify(cachedUploads));
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/multipart/progressTracker.mjs
var getConcurrentUploadsProgressTracker = ({ size, onProgress }) => {
  const transferredBytesPerListener = [];
  const getTransferredBytes = () => transferredBytesPerListener.reduce((acc, transferredBytes) => acc + transferredBytes, 0);
  return {
    getOnProgressListener: () => {
      transferredBytesPerListener.push(0);
      const listenerIndex = transferredBytesPerListener.length - 1;
      return (event) => {
        const { transferredBytes } = event;
        transferredBytesPerListener[listenerIndex] = transferredBytes;
        onProgress == null ? void 0 : onProgress({
          transferredBytes: getTransferredBytes(),
          totalBytes: size
        });
      };
    }
  };
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/multipart/initialUpload.mjs
var loadOrCreateMultipartUpload = async ({ s3Config, data, size, contentType, bucket, accessLevel, keyPrefix, key, contentDisposition, contentEncoding, metadata, abortSignal, checksumAlgorithm, optionsHash, resumableUploadsCache, expectedBucketOwner }) => {
  const finalKey = keyPrefix !== void 0 ? keyPrefix + key : key;
  let cachedUpload;
  if (!resumableUploadsCache) {
    logger2.debug("uploaded cache instance cannot be determined, skipping cache.");
    cachedUpload = void 0;
  } else {
    const uploadCacheKey = getUploadsCacheKey({
      size,
      contentType,
      file: data instanceof File ? data : void 0,
      bucket,
      accessLevel,
      key,
      optionsHash
    });
    const cachedUploadParts = await findCachedUploadPartsAndEvictExpired({
      s3Config,
      cacheKey: uploadCacheKey,
      bucket,
      finalKey,
      resumableUploadsCache
    });
    cachedUpload = cachedUploadParts ? { ...cachedUploadParts, uploadCacheKey } : void 0;
  }
  if (cachedUpload) {
    return {
      uploadId: cachedUpload.uploadId,
      cachedParts: cachedUpload.parts,
      finalCrc32: cachedUpload.finalCrc32
    };
  } else {
    const finalCrc32 = checksumAlgorithm === CHECKSUM_ALGORITHM_CRC32 ? await calculateContentCRC32(data) : void 0;
    const { UploadId } = await createMultipartUpload({
      ...s3Config,
      abortSignal
    }, {
      Bucket: bucket,
      Key: finalKey,
      ContentType: contentType,
      ContentDisposition: constructContentDisposition(contentDisposition),
      ContentEncoding: contentEncoding,
      Metadata: metadata,
      ChecksumAlgorithm: finalCrc32 ? "CRC32" : void 0,
      ChecksumType: finalCrc32 ? "FULL_OBJECT" : void 0,
      ExpectedBucketOwner: expectedBucketOwner
    });
    if (resumableUploadsCache) {
      const uploadCacheKey = getUploadsCacheKey({
        size,
        contentType,
        file: data instanceof File ? data : void 0,
        bucket,
        accessLevel,
        key,
        optionsHash
      });
      await cacheMultipartUpload(resumableUploadsCache, uploadCacheKey, {
        uploadId: UploadId,
        bucket,
        key,
        finalCrc32,
        fileName: data instanceof File ? data.name : ""
      });
    }
    return {
      uploadId: UploadId,
      cachedParts: [],
      finalCrc32
    };
  }
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/multipart/calculatePartSize.mjs
var calculatePartSize = (totalSize) => {
  if (!totalSize) {
    return DEFAULT_PART_SIZE;
  }
  let partSize = DEFAULT_PART_SIZE;
  let partsCount = Math.ceil(totalSize / partSize);
  while (partsCount > MAX_PARTS_COUNT) {
    partSize *= 2;
    partsCount = Math.ceil(totalSize / partSize);
  }
  return partSize;
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/multipart/getDataChunker.mjs
var getDataChunker = (data, totalSize) => {
  const partSize = calculatePartSize(totalSize);
  if (data instanceof Blob) {
    return helper(data, 0, data.size, partSize);
  } else if (ArrayBuffer.isView(data)) {
    return helper(data.buffer, data.byteOffset, data.byteLength, partSize);
  } else if (data instanceof ArrayBuffer) {
    return helper(data, 0, data.byteLength, partSize);
  } else if (typeof data === "string") {
    const blob = new Blob([data]);
    return getDataChunker(blob, blob.size);
  } else {
    throw new StorageError({
      name: StorageValidationErrorCode.InvalidUploadSource,
      ...validationErrorMap[StorageValidationErrorCode.InvalidUploadSource]
    });
  }
};
var helper = function* (buffer, byteOffset, byteLength2, partSize) {
  let partNumber = 1;
  let startByte = byteOffset;
  let endByte = byteOffset + Math.min(partSize, byteLength2);
  while (endByte < byteLength2 + byteOffset) {
    yield {
      partNumber,
      data: buffer.slice(startByte, endByte),
      size: partSize
    };
    partNumber += 1;
    startByte = endByte;
    endByte = startByte + partSize;
  }
  yield {
    partNumber,
    data: buffer.slice(startByte, byteLength2 + byteOffset),
    size: byteLength2 + byteOffset - startByte
  };
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/multipart/uploadHandlers.mjs
var getMultipartUploadHandlers = (uploadDataInput, size) => {
  let resolveCallback;
  let rejectCallback;
  let inProgressUpload;
  let resolvedS3Config;
  let abortController;
  let resolvedAccessLevel;
  let resolvedBucket;
  let resolvedKeyPrefix;
  let resolvedIdentityId;
  let uploadCacheKey;
  let finalKey;
  let expectedBucketOwner;
  let isAbortSignalFromPause = false;
  const { resumableUploadsCache } = uploadDataInput.options ?? {};
  const startUpload = async () => {
    const { options: uploadDataOptions, data } = uploadDataInput;
    const resolvedS3Options = await resolveS3ConfigAndInput(Amplify, uploadDataInput);
    abortController = new AbortController();
    isAbortSignalFromPause = false;
    resolvedS3Config = resolvedS3Options.s3Config;
    resolvedBucket = resolvedS3Options.bucket;
    resolvedIdentityId = resolvedS3Options.identityId;
    expectedBucketOwner = uploadDataOptions == null ? void 0 : uploadDataOptions.expectedBucketOwner;
    const { inputType, objectKey } = validateStorageOperationInput(uploadDataInput, resolvedIdentityId);
    const { contentDisposition, contentEncoding, contentType = "application/octet-stream", metadata, preventOverwrite, onProgress } = uploadDataOptions ?? {};
    finalKey = objectKey;
    if (inputType === STORAGE_INPUT_KEY) {
      const accessLevel = uploadDataOptions == null ? void 0 : uploadDataOptions.accessLevel;
      resolvedKeyPrefix = resolvedS3Options.keyPrefix;
      finalKey = resolvedKeyPrefix + objectKey;
      resolvedAccessLevel = resolveAccessLevel(accessLevel);
    }
    const optionsHash = await calculateContentCRC32(serializeUploadOptions(uploadDataOptions));
    if (!inProgressUpload) {
      const { uploadId, cachedParts, finalCrc32 } = await loadOrCreateMultipartUpload({
        s3Config: resolvedS3Config,
        accessLevel: resolvedAccessLevel,
        bucket: resolvedBucket,
        keyPrefix: resolvedKeyPrefix,
        key: objectKey,
        contentType,
        contentDisposition,
        contentEncoding,
        metadata,
        data,
        size,
        abortSignal: abortController.signal,
        checksumAlgorithm: uploadDataOptions == null ? void 0 : uploadDataOptions.checksumAlgorithm,
        optionsHash,
        resumableUploadsCache,
        expectedBucketOwner
      });
      inProgressUpload = {
        uploadId,
        completedParts: cachedParts,
        finalCrc32
      };
    }
    uploadCacheKey = size ? getUploadsCacheKey({
      file: data instanceof File ? data : void 0,
      accessLevel: resolvedAccessLevel,
      contentType: uploadDataOptions == null ? void 0 : uploadDataOptions.contentType,
      bucket: resolvedBucket,
      size,
      key: objectKey,
      optionsHash
    }) : void 0;
    const dataChunker = getDataChunker(data, size);
    const completedPartNumberSet = new Set(inProgressUpload.completedParts.map(({ PartNumber }) => PartNumber));
    const onPartUploadCompletion = (partNumber, eTag2, crc322) => {
      inProgressUpload == null ? void 0 : inProgressUpload.completedParts.push({
        PartNumber: partNumber,
        ETag: eTag2,
        // TODO: crc32 can always be added once RN also has an implementation
        ...crc322 ? { ChecksumCRC32: crc322 } : {}
      });
    };
    const concurrentUploadsProgressTracker = getConcurrentUploadsProgressTracker({
      size,
      onProgress
    });
    const concurrentUploadPartExecutors = [];
    for (let index = 0; index < DEFAULT_QUEUE_SIZE; index++) {
      concurrentUploadPartExecutors.push(uploadPartExecutor({
        dataChunkerGenerator: dataChunker,
        completedPartNumberSet,
        s3Config: resolvedS3Config,
        abortSignal: abortController.signal,
        bucket: resolvedBucket,
        finalKey,
        uploadId: inProgressUpload.uploadId,
        onPartUploadCompletion,
        onProgress: concurrentUploadsProgressTracker.getOnProgressListener(),
        isObjectLockEnabled: resolvedS3Options.isObjectLockEnabled,
        useCRC32Checksum: Boolean(inProgressUpload.finalCrc32),
        expectedBucketOwner
      }));
    }
    await Promise.all(concurrentUploadPartExecutors);
    validateCompletedParts(inProgressUpload.completedParts, size);
    const { ETag: eTag } = await completeMultipartUpload({
      ...resolvedS3Config,
      abortSignal: abortController.signal,
      userAgentValue: getStorageUserAgentValue(StorageAction.UploadData)
    }, {
      Bucket: resolvedBucket,
      Key: finalKey,
      UploadId: inProgressUpload.uploadId,
      ChecksumCRC32: inProgressUpload.finalCrc32,
      ChecksumType: inProgressUpload.finalCrc32 ? "FULL_OBJECT" : void 0,
      IfNoneMatch: preventOverwrite ? "*" : void 0,
      MultipartUpload: {
        Parts: sortUploadParts(inProgressUpload.completedParts)
      },
      ExpectedBucketOwner: expectedBucketOwner
    });
    if (!inProgressUpload.finalCrc32) {
      const { ContentLength: uploadedObjectSize, $metadata } = await headObject(resolvedS3Config, {
        Bucket: resolvedBucket,
        Key: finalKey,
        ExpectedBucketOwner: expectedBucketOwner
      });
      if (uploadedObjectSize && uploadedObjectSize !== size) {
        throw new StorageError({
          name: "Error",
          message: `Upload failed. Expected object size ${size}, but got ${uploadedObjectSize}.`,
          metadata: $metadata
        });
      }
    }
    if (resumableUploadsCache && uploadCacheKey) {
      await removeCachedUpload(resumableUploadsCache, uploadCacheKey);
    }
    const result = {
      eTag,
      contentType,
      metadata
    };
    return inputType === STORAGE_INPUT_KEY ? { key: objectKey, ...result } : { path: objectKey, ...result };
  };
  const startUploadWithResumability = () => startUpload().then(resolveCallback).catch((error) => {
    const abortSignal = abortController == null ? void 0 : abortController.signal;
    if ((abortSignal == null ? void 0 : abortSignal.aborted) && isAbortSignalFromPause) {
      logger2.debug("upload paused.");
    } else {
      rejectCallback(error);
    }
  });
  const multipartUploadJob = () => new Promise((resolve, reject) => {
    resolveCallback = resolve;
    rejectCallback = reject;
    startUploadWithResumability();
  });
  const onPause = () => {
    isAbortSignalFromPause = true;
    abortController == null ? void 0 : abortController.abort();
  };
  const onResume = () => {
    startUploadWithResumability();
  };
  const onCancel = (message) => {
    abortController == null ? void 0 : abortController.abort(message);
    const cancelUpload = async () => {
      if (uploadCacheKey && resumableUploadsCache) {
        await removeCachedUpload(resumableUploadsCache, uploadCacheKey);
      }
      await abortMultipartUpload(resolvedS3Config, {
        Bucket: resolvedBucket,
        Key: finalKey,
        UploadId: inProgressUpload == null ? void 0 : inProgressUpload.uploadId,
        ExpectedBucketOwner: expectedBucketOwner
      });
    };
    cancelUpload().catch((e) => {
      logger2.debug("error when cancelling upload task.", e);
    });
    rejectCallback(
      // Internal error that should not be exposed to the users. They should use isCancelError() to check if
      // the error is caused by cancel().
      new CanceledError(message ? { message } : void 0)
    );
  };
  return {
    multipartUploadJob,
    onPause,
    onResume,
    onCancel
  };
};
var resolveAccessLevel = (accessLevel) => {
  var _a, _b;
  return accessLevel ?? ((_b = (_a = Amplify.libraryOptions.Storage) == null ? void 0 : _a.S3) == null ? void 0 : _b.defaultAccessLevel) ?? DEFAULT_ACCESS_LEVEL;
};
var validateCompletedParts = (completedParts, size) => {
  const partsExpected = Math.ceil(size / calculatePartSize(size));
  const validPartCount = completedParts.length === partsExpected;
  const sorted = sortUploadParts(completedParts);
  const validPartNumbers = sorted.every((part, index) => part.PartNumber === index + 1);
  if (!validPartCount || !validPartNumbers) {
    throw new IntegrityError();
  }
};
var sortUploadParts = (parts) => {
  return [...parts].sort((partA, partB) => partA.PartNumber - partB.PartNumber);
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/uploadData/index.mjs
var uploadData = (input) => {
  const { data } = input;
  const dataByteLength = byteLength(data);
  assertValidationError(dataByteLength !== void 0, StorageValidationErrorCode.InvalidUploadSource);
  assertValidationError(dataByteLength <= MAX_OBJECT_SIZE, StorageValidationErrorCode.ObjectIsTooLarge);
  if (dataByteLength <= DEFAULT_PART_SIZE) {
    const abortController = new AbortController();
    return createUploadTask({
      isMultipartUpload: false,
      job: putObjectJob(input, abortController.signal, dataByteLength),
      onCancel: (message) => {
        abortController.abort(message);
      }
    });
  } else {
    const { multipartUploadJob, onPause, onResume, onCancel } = getMultipartUploadHandlers(input, dataByteLength);
    return createUploadTask({
      isMultipartUpload: true,
      job: multipartUploadJob,
      onCancel: (message) => {
        onCancel(message);
      },
      onPause,
      onResume
    });
  }
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/uploadData.mjs
function uploadData2(input) {
  return uploadData({
    ...input,
    options: {
      ...input == null ? void 0 : input.options,
      // This option enables caching in-progress multipart uploads.
      // It's ONLY needed for client-side API.
      resumableUploadsCache: defaultStorage
    }
  });
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/downloadData.mjs
var import_fast_xml_parser17 = __toESM(require_fast_xml_parser(), 1);
var import_buffer17 = __toESM(require_buffer(), 1);
var downloadData = (input) => {
  const abortController = new AbortController();
  const downloadTask = createDownloadTask({
    job: downloadDataJob(input, abortController.signal),
    onCancel: (message) => {
      abortController.abort(message);
    }
  });
  return downloadTask;
};
var downloadDataJob = (downloadDataInput, abortSignal) => async () => {
  const { options: downloadDataOptions } = downloadDataInput;
  const { bucket, keyPrefix, s3Config, identityId } = await resolveS3ConfigAndInput(Amplify, downloadDataInput);
  const { inputType, objectKey } = validateStorageOperationInput(downloadDataInput, identityId);
  validateBucketOwnerID(downloadDataOptions == null ? void 0 : downloadDataOptions.expectedBucketOwner);
  const finalKey = inputType === STORAGE_INPUT_KEY ? keyPrefix + objectKey : objectKey;
  logger2.debug(`download ${objectKey} from ${finalKey}.`);
  const { Body: body, LastModified: lastModified, ContentLength: size, ETag: eTag, Metadata: metadata, VersionId: versionId, ContentType: contentType } = await getObject({
    ...s3Config,
    abortSignal,
    onDownloadProgress: downloadDataOptions == null ? void 0 : downloadDataOptions.onProgress,
    userAgentValue: getStorageUserAgentValue(StorageAction.DownloadData)
  }, {
    Bucket: bucket,
    Key: finalKey,
    ...(downloadDataOptions == null ? void 0 : downloadDataOptions.bytesRange) && {
      Range: `bytes=${downloadDataOptions.bytesRange.start}-${downloadDataOptions.bytesRange.end}`
    },
    ExpectedBucketOwner: downloadDataOptions == null ? void 0 : downloadDataOptions.expectedBucketOwner
  });
  const result = {
    body,
    lastModified,
    size,
    contentType,
    eTag,
    metadata,
    versionId
  };
  return inputType === STORAGE_INPUT_KEY ? { key: objectKey, ...result } : { path: objectKey, ...result };
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/downloadData.mjs
function downloadData2(input) {
  return downloadData(input);
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/remove.mjs
var import_fast_xml_parser18 = __toESM(require_fast_xml_parser(), 1);
var import_buffer18 = __toESM(require_buffer(), 1);
var remove = async (amplify, input) => {
  var _a, _b;
  const { s3Config, keyPrefix, bucket, identityId } = await resolveS3ConfigAndInput(amplify, input);
  const { inputType, objectKey } = validateStorageOperationInput(input, identityId);
  validateBucketOwnerID((_a = input.options) == null ? void 0 : _a.expectedBucketOwner);
  let finalKey;
  if (inputType === STORAGE_INPUT_KEY) {
    finalKey = `${keyPrefix}${objectKey}`;
    logger2.debug(`remove "${objectKey}" from "${finalKey}".`);
  } else {
    finalKey = objectKey;
    logger2.debug(`removing object in path "${finalKey}"`);
  }
  await deleteObject({
    ...s3Config,
    userAgentValue: getStorageUserAgentValue(StorageAction.Remove)
  }, {
    Bucket: bucket,
    Key: finalKey,
    ExpectedBucketOwner: (_b = input.options) == null ? void 0 : _b.expectedBucketOwner
  });
  return inputType === STORAGE_INPUT_KEY ? {
    key: objectKey
  } : {
    path: objectKey
  };
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/remove.mjs
function remove2(input) {
  return remove(Amplify, input);
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/list.mjs
var import_fast_xml_parser19 = __toESM(require_fast_xml_parser(), 1);
var import_buffer19 = __toESM(require_buffer(), 1);

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/validateStorageOperationInputWithPrefix.mjs
var _isInputWithPath = (input) => {
  return input.path !== void 0;
};
var validateStorageOperationInputWithPrefix = (input, identityId) => {
  assertValidationError(!(input.prefix && input.path), StorageValidationErrorCode.InvalidStorageOperationPrefixInput);
  if (_isInputWithPath(input)) {
    const { path } = input;
    const objectKey = typeof path === "string" ? path : path({ identityId: resolveIdentityId(identityId) });
    assertValidationError(!objectKey.startsWith("/"), StorageValidationErrorCode.InvalidStoragePathInput);
    return {
      inputType: STORAGE_INPUT_PATH,
      objectKey
    };
  } else {
    return { inputType: STORAGE_INPUT_PREFIX, objectKey: input.prefix ?? "" };
  }
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/utils/urlDecoder.mjs
var urlDecode = (value) => {
  return decodeURIComponent(value.replace(/\+/g, " "));
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/list.mjs
var MAX_PAGE_SIZE = 1e3;
var list = async (amplify, input) => {
  const { options = {} } = input;
  const { s3Config, bucket, keyPrefix: generatedPrefix, identityId } = await resolveS3ConfigAndInput(amplify, input);
  const { inputType, objectKey } = validateStorageOperationInputWithPrefix(input, identityId);
  validateBucketOwnerID(options.expectedBucketOwner);
  const isInputWithPrefix2 = inputType === STORAGE_INPUT_PREFIX;
  if ((options == null ? void 0 : options.listAll) && ((options == null ? void 0 : options.pageSize) || (options == null ? void 0 : options.nextToken))) {
    const anyOptions = options;
    logger2.debug(`listAll is set to true, ignoring ${(anyOptions == null ? void 0 : anyOptions.pageSize) ? `pageSize: ${anyOptions == null ? void 0 : anyOptions.pageSize}` : ""} ${(anyOptions == null ? void 0 : anyOptions.nextToken) ? `nextToken: ${anyOptions == null ? void 0 : anyOptions.nextToken}` : ""}.`);
  }
  const listParams = {
    Bucket: bucket,
    Prefix: isInputWithPrefix2 ? `${generatedPrefix}${objectKey}` : objectKey,
    MaxKeys: (options == null ? void 0 : options.listAll) ? void 0 : options == null ? void 0 : options.pageSize,
    ContinuationToken: (options == null ? void 0 : options.listAll) ? void 0 : options == null ? void 0 : options.nextToken,
    Delimiter: getDelimiter(options),
    ExpectedBucketOwner: options == null ? void 0 : options.expectedBucketOwner,
    EncodingType: "url"
  };
  logger2.debug(`listing items from "${listParams.Prefix}"`);
  const listInputArgs = {
    s3Config,
    listParams
  };
  if (options.listAll) {
    if (isInputWithPrefix2) {
      return _listAllWithPrefix({
        ...listInputArgs,
        generatedPrefix
      });
    } else {
      return _listAllWithPath(listInputArgs);
    }
  } else {
    if (isInputWithPrefix2) {
      return _listWithPrefix({ ...listInputArgs, generatedPrefix });
    } else {
      return _listWithPath(listInputArgs);
    }
  }
};
var _listAllWithPrefix = async ({ s3Config, listParams, generatedPrefix }) => {
  const listResult = [];
  let continuationToken = listParams.ContinuationToken;
  do {
    const { items: pageResults, nextToken: pageNextToken } = await _listWithPrefix({
      generatedPrefix,
      s3Config,
      listParams: {
        ...listParams,
        ContinuationToken: continuationToken,
        MaxKeys: MAX_PAGE_SIZE
      }
    });
    listResult.push(...pageResults);
    continuationToken = pageNextToken;
  } while (continuationToken);
  return {
    items: listResult
  };
};
var _listWithPrefix = async ({ s3Config, listParams, generatedPrefix }) => {
  const listParamsClone = { ...listParams };
  if (!listParamsClone.MaxKeys || listParamsClone.MaxKeys > MAX_PAGE_SIZE) {
    logger2.debug(`defaulting pageSize to ${MAX_PAGE_SIZE}.`);
    listParamsClone.MaxKeys = MAX_PAGE_SIZE;
  }
  const response = await listObjectsV2({
    ...s3Config,
    userAgentValue: getStorageUserAgentValue(StorageAction.List)
  }, listParamsClone);
  const listOutput = decodeEncodedElements(response);
  validateEchoedElements(listParamsClone, listOutput);
  if (!(listOutput == null ? void 0 : listOutput.Contents)) {
    return {
      items: []
    };
  }
  return {
    items: listOutput.Contents.map((item) => ({
      key: generatedPrefix ? item.Key.substring(generatedPrefix.length) : item.Key,
      eTag: item.ETag,
      lastModified: item.LastModified,
      size: item.Size
    })),
    nextToken: listOutput.NextContinuationToken
  };
};
var _listAllWithPath = async ({ s3Config, listParams }) => {
  const listResult = [];
  const excludedSubpaths = [];
  let continuationToken = listParams.ContinuationToken;
  do {
    const { items: pageResults, excludedSubpaths: pageExcludedSubpaths, nextToken: pageNextToken } = await _listWithPath({
      s3Config,
      listParams: {
        ...listParams,
        ContinuationToken: continuationToken,
        MaxKeys: MAX_PAGE_SIZE
      }
    });
    listResult.push(...pageResults);
    excludedSubpaths.push(...pageExcludedSubpaths ?? []);
    continuationToken = pageNextToken;
  } while (continuationToken);
  return {
    items: listResult,
    excludedSubpaths
  };
};
var _listWithPath = async ({ s3Config, listParams }) => {
  const listParamsClone = { ...listParams };
  if (!listParamsClone.MaxKeys || listParamsClone.MaxKeys > MAX_PAGE_SIZE) {
    logger2.debug(`defaulting pageSize to ${MAX_PAGE_SIZE}.`);
    listParamsClone.MaxKeys = MAX_PAGE_SIZE;
  }
  const response = await listObjectsV2({
    ...s3Config,
    userAgentValue: getStorageUserAgentValue(StorageAction.List)
  }, listParamsClone);
  const listOutput = decodeEncodedElements(response);
  validateEchoedElements(listParamsClone, listOutput);
  const { Contents: contents, NextContinuationToken: nextContinuationToken, CommonPrefixes: commonPrefixes } = listOutput;
  const excludedSubpaths = commonPrefixes && mapCommonPrefixesToExcludedSubpaths(commonPrefixes);
  if (!contents) {
    return {
      items: [],
      nextToken: nextContinuationToken,
      excludedSubpaths
    };
  }
  return {
    items: contents.map((item) => ({
      path: item.Key,
      eTag: item.ETag,
      lastModified: item.LastModified,
      size: item.Size
    })),
    nextToken: nextContinuationToken,
    excludedSubpaths
  };
};
var mapCommonPrefixesToExcludedSubpaths = (commonPrefixes) => {
  return commonPrefixes.reduce((mappedSubpaths, { Prefix }) => {
    if (Prefix) {
      mappedSubpaths.push(Prefix);
    }
    return mappedSubpaths;
  }, []);
};
var getDelimiter = (options) => {
  var _a, _b;
  if (((_a = options == null ? void 0 : options.subpathStrategy) == null ? void 0 : _a.strategy) === "exclude") {
    return ((_b = options == null ? void 0 : options.subpathStrategy) == null ? void 0 : _b.delimiter) ?? DEFAULT_DELIMITER;
  }
};
var validateEchoedElements = (listInput, listOutput) => {
  const validEchoedParameters = listInput.Bucket === listOutput.Name && listInput.Delimiter === listOutput.Delimiter && listInput.MaxKeys === listOutput.MaxKeys && listInput.Prefix === listOutput.Prefix && listInput.ContinuationToken === listOutput.ContinuationToken;
  if (!validEchoedParameters) {
    throw new IntegrityError({ metadata: listOutput.$metadata });
  }
};
var decodeEncodedElements = (listOutput) => {
  if (listOutput.EncodingType !== "url") {
    return listOutput;
  }
  const decodedListOutput = { ...listOutput };
  ["Delimiter", "Prefix", "StartAfter"].forEach((prop) => {
    const value = listOutput[prop];
    if (typeof value === "string") {
      decodedListOutput[prop] = urlDecode(value);
    }
  });
  if (listOutput.Contents) {
    decodedListOutput.Contents = listOutput.Contents.map((content) => ({
      ...content,
      Key: content.Key ? urlDecode(content.Key) : content.Key
    }));
  }
  if (listOutput.CommonPrefixes) {
    decodedListOutput.CommonPrefixes = listOutput.CommonPrefixes.map((content) => ({
      ...content,
      Prefix: content.Prefix ? urlDecode(content.Prefix) : content.Prefix
    }));
  }
  return decodedListOutput;
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/list.mjs
function list2(input) {
  return list(Amplify, input ?? {});
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/getProperties.mjs
var import_fast_xml_parser20 = __toESM(require_fast_xml_parser(), 1);
var import_buffer20 = __toESM(require_buffer(), 1);
var getProperties = async (amplify, input, action) => {
  var _a, _b;
  const { s3Config, bucket, keyPrefix, identityId } = await resolveS3ConfigAndInput(amplify, input);
  const { inputType, objectKey } = validateStorageOperationInput(input, identityId);
  validateBucketOwnerID((_a = input.options) == null ? void 0 : _a.expectedBucketOwner);
  const finalKey = inputType === STORAGE_INPUT_KEY ? keyPrefix + objectKey : objectKey;
  logger2.debug(`get properties of ${objectKey} from ${finalKey}`);
  const response = await headObject({
    ...s3Config,
    userAgentValue: getStorageUserAgentValue(action ?? StorageAction.GetProperties)
  }, {
    Bucket: bucket,
    Key: finalKey,
    ExpectedBucketOwner: (_b = input.options) == null ? void 0 : _b.expectedBucketOwner
  });
  const result = {
    contentType: response.ContentType,
    size: response.ContentLength,
    eTag: response.ETag,
    lastModified: response.LastModified,
    metadata: response.Metadata,
    versionId: response.VersionId
  };
  return inputType === STORAGE_INPUT_KEY ? { key: objectKey, ...result } : { path: objectKey, ...result };
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/getProperties.mjs
function getProperties2(input) {
  return getProperties(Amplify, input);
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/copy.mjs
var import_fast_xml_parser21 = __toESM(require_fast_xml_parser(), 1);
var import_buffer21 = __toESM(require_buffer(), 1);
var isCopyInputWithPath = (input) => isInputWithPath(input.source);
var storageBucketAssertion = (sourceBucket, destBucket) => {
  assertValidationError(
    // Both src & dest bucket option is present is acceptable
    sourceBucket !== void 0 && destBucket !== void 0 || // or both are undefined is also acceptable
    !destBucket && !sourceBucket,
    StorageValidationErrorCode.InvalidCopyOperationStorageBucket
  );
};
var copy = async (amplify, input) => {
  return isCopyInputWithPath(input) ? copyWithPath(amplify, input) : copyWithKey(amplify, input);
};
var copyWithPath = async (amplify, input) => {
  var _a, _b, _c, _d, _e;
  const { source, destination } = input;
  storageBucketAssertion(source.bucket, destination.bucket);
  const { bucket: sourceBucket } = await resolveS3ConfigAndInput(amplify, {
    path: input.source.path,
    options: {
      locationCredentialsProvider: (_a = input.options) == null ? void 0 : _a.locationCredentialsProvider,
      ...input.source
    }
  });
  const { s3Config, bucket: destBucket, identityId } = await resolveS3ConfigAndInput(amplify, {
    path: input.destination.path,
    options: {
      locationCredentialsProvider: (_b = input.options) == null ? void 0 : _b.locationCredentialsProvider,
      customEndpoint: (_c = input.options) == null ? void 0 : _c.customEndpoint,
      ...input.destination
    }
  });
  assertValidationError(!!source.path, StorageValidationErrorCode.NoSourcePath);
  assertValidationError(!!destination.path, StorageValidationErrorCode.NoDestinationPath);
  const { objectKey: sourcePath } = validateStorageOperationInput(source, identityId);
  const { objectKey: destinationPath } = validateStorageOperationInput(destination, identityId);
  validateBucketOwnerID(source.expectedBucketOwner);
  validateBucketOwnerID(destination.expectedBucketOwner);
  const finalCopySource = `${sourceBucket}/${sourcePath}`;
  const finalCopyDestination = destinationPath;
  logger2.debug(`copying "${finalCopySource}" to "${finalCopyDestination}".`);
  await serviceCopy({
    source: finalCopySource,
    destination: finalCopyDestination,
    bucket: destBucket,
    s3Config,
    notModifiedSince: input.source.notModifiedSince,
    eTag: input.source.eTag,
    expectedSourceBucketOwner: (_d = input.source) == null ? void 0 : _d.expectedBucketOwner,
    expectedBucketOwner: (_e = input.destination) == null ? void 0 : _e.expectedBucketOwner
  });
  return { path: finalCopyDestination };
};
var copyWithKey = async (amplify, input) => {
  var _a, _b, _c, _d;
  const { source, destination } = input;
  storageBucketAssertion(source.bucket, destination.bucket);
  assertValidationError(!!source.key, StorageValidationErrorCode.NoSourceKey);
  assertValidationError(!!destination.key, StorageValidationErrorCode.NoDestinationKey);
  validateBucketOwnerID(source.expectedBucketOwner);
  validateBucketOwnerID(destination.expectedBucketOwner);
  const { bucket: sourceBucket, keyPrefix: sourceKeyPrefix } = await resolveS3ConfigAndInput(amplify, {
    ...input,
    options: {
      // @ts-expect-error: 'options' does not exist on type 'CopyInput'. In case of JS users set the location
      // credentials provider option, resolveS3ConfigAndInput will throw validation error.
      locationCredentialsProvider: (_a = input.options) == null ? void 0 : _a.locationCredentialsProvider,
      ...input.source
    }
  });
  const { s3Config, bucket: destBucket, keyPrefix: destinationKeyPrefix } = await resolveS3ConfigAndInput(amplify, {
    ...input,
    options: {
      // @ts-expect-error: 'options' does not exist on type 'CopyInput'. In case of JS users set the location
      // credentials provider option, resolveS3ConfigAndInput will throw validation error.
      locationCredentialsProvider: (_b = input.options) == null ? void 0 : _b.locationCredentialsProvider,
      ...input.destination
    }
  });
  const finalCopySource = `${sourceBucket}/${sourceKeyPrefix}${source.key}`;
  const finalCopyDestination = `${destinationKeyPrefix}${destination.key}`;
  logger2.debug(`copying "${finalCopySource}" to "${finalCopyDestination}".`);
  await serviceCopy({
    source: finalCopySource,
    destination: finalCopyDestination,
    bucket: destBucket,
    s3Config,
    notModifiedSince: input.source.notModifiedSince,
    eTag: input.source.eTag,
    expectedSourceBucketOwner: (_c = input.source) == null ? void 0 : _c.expectedBucketOwner,
    expectedBucketOwner: (_d = input.destination) == null ? void 0 : _d.expectedBucketOwner
  });
  return {
    key: destination.key
  };
};
var serviceCopy = async ({ source, destination, bucket, s3Config, notModifiedSince, eTag, expectedSourceBucketOwner, expectedBucketOwner }) => {
  await copyObject({
    ...s3Config,
    userAgentValue: getStorageUserAgentValue(StorageAction.Copy)
  }, {
    Bucket: bucket,
    CopySource: source,
    Key: destination,
    MetadataDirective: "COPY",
    // Copies over metadata like contentType as well
    CopySourceIfMatch: eTag,
    CopySourceIfUnmodifiedSince: notModifiedSince,
    ExpectedSourceBucketOwner: expectedSourceBucketOwner,
    ExpectedBucketOwner: expectedBucketOwner
  });
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/copy.mjs
function copy2(input) {
  return copy(Amplify, input);
}

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/internal/getUrl.mjs
var import_fast_xml_parser22 = __toESM(require_fast_xml_parser(), 1);
var import_buffer22 = __toESM(require_buffer(), 1);
var getUrl = async (amplify, input) => {
  const { options: getUrlOptions } = input;
  const { s3Config, keyPrefix, bucket, identityId } = await resolveS3ConfigAndInput(amplify, input);
  const { inputType, objectKey } = validateStorageOperationInput(input, identityId);
  validateBucketOwnerID(getUrlOptions == null ? void 0 : getUrlOptions.expectedBucketOwner);
  const finalKey = inputType === STORAGE_INPUT_KEY ? keyPrefix + objectKey : objectKey;
  if (getUrlOptions == null ? void 0 : getUrlOptions.validateObjectExistence) {
    await getProperties(amplify, input, StorageAction.GetUrl);
  }
  let urlExpirationInSec = (getUrlOptions == null ? void 0 : getUrlOptions.expiresIn) ?? DEFAULT_PRESIGN_EXPIRATION;
  const resolvedCredential = typeof s3Config.credentials === "function" ? await s3Config.credentials() : s3Config.credentials;
  const awsCredExpiration = resolvedCredential.expiration;
  if (awsCredExpiration) {
    const awsCredExpirationInSec = Math.floor((awsCredExpiration.getTime() - Date.now()) / 1e3);
    urlExpirationInSec = Math.min(awsCredExpirationInSec, urlExpirationInSec);
  }
  const maxUrlExpirationInSec = MAX_URL_EXPIRATION / 1e3;
  assertValidationError(urlExpirationInSec <= maxUrlExpirationInSec, StorageValidationErrorCode.UrlExpirationMaxLimitExceed);
  return {
    url: await getPresignedGetObjectUrl({
      ...s3Config,
      credentials: resolvedCredential,
      expiration: urlExpirationInSec
    }, {
      Bucket: bucket,
      Key: finalKey,
      ...(getUrlOptions == null ? void 0 : getUrlOptions.contentDisposition) && {
        ResponseContentDisposition: constructContentDisposition(getUrlOptions.contentDisposition)
      },
      ...(getUrlOptions == null ? void 0 : getUrlOptions.contentType) && {
        ResponseContentType: getUrlOptions.contentType
      },
      ExpectedBucketOwner: getUrlOptions == null ? void 0 : getUrlOptions.expectedBucketOwner
    }),
    expiresAt: new Date(Date.now() + urlExpirationInSec * 1e3)
  };
};

// node_modules/@aws-amplify/storage/dist/esm/providers/s3/apis/getUrl.mjs
function getUrl2(input) {
  return getUrl(Amplify, input);
}

export {
  StorageError,
  isCancelError,
  DEFAULT_PART_SIZE,
  uploadData2 as uploadData,
  downloadData2 as downloadData,
  remove2 as remove,
  list2 as list,
  getProperties2 as getProperties,
  copy2 as copy,
  getUrl2 as getUrl
};
/*! Bundled license information:

crc-32/crc32.js:
  (*! crc32.js (C) 2014-present SheetJS -- http://sheetjs.com *)
*/
//# sourceMappingURL=chunk-MPYNH4EY.js.map
